{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e76795-6c2c-4e2b-801d-3aa9c8b82fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 122 not upgraded.\n",
      "Requirement already satisfied: torchcodec==0.3.0 in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets==3.6.0 in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.36.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
      "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.3.1)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.14.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.4.1+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.57.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.22.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# torch 2.4에서만 해당하는 버전\n",
    "!apt-get update\n",
    "!apt-get install -y ffmpeg\n",
    "!pip install torchcodec==0.3.0\n",
    "!pip install datasets==3.6.0\n",
    "!pip install librosa soundfile jiwer evaluate huggingface_hub peft Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434545df-5d51-4e06-8c9c-0a3af755d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Audio\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "from transformers import (\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9041a0ef-31df-4d18-b0f7-80960c653c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시드가 8282로 설정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 설정\n",
    "RANDOM_SEED = 8282\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "print(f\"랜덤 시드가 {RANDOM_SEED}로 설정되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49aa855b-53f0-4135-a323-c8853a87aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 3400\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 340\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"daje/korean-address-voice-v2\")\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ad7bd3-8d3d-44d7-8e39-9236fadf7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"openai/whisper-large-v3-turbo\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME, language=\"Korean\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME, language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae9a65e-924b-41ef-9805-68f23701b660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울특별시영등포구압구정로136 SK뷰293동3047호'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = datasets[\"train\"][0][\"text\"]\n",
    "input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d0bfae-4e5c-402f-bb83-9e6cd0f81644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력:                서울특별시영등포구압구정로136 SK뷰293동3047호\n",
      "특수토큰 포함 디코딩:    <|startoftranscript|><|ko|><|transcribe|><|notimestamps|>서울특별시영등포구압구정로136 SK뷰293동3047호<|endoftext|>\n",
      "특수토큰 제외 디코딩:    서울특별시영등포구압구정로136 SK뷰293동3047호\n",
      "원본과 동일 여부:       True\n"
     ]
    }
   ],
   "source": [
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"입력:                {input_str}\")\n",
    "print(f\"특수토큰 포함 디코딩:    {decoded_with_special}\")\n",
    "print(f\"특수토큰 제외 디코딩:    {decoded_str}\")\n",
    "print(f\"원본과 동일 여부:       {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674713db-eb69-4de1-8f46-149790683ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': '서울특별시영등포구압구정로136_SK뷰293동3047호.mp3', 'array': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "       2.81896450e-06, 2.82983729e-06, 8.46276862e-08]), 'sampling_rate': 24000}, 'text': '서울특별시영등포구압구정로136 SK뷰293동3047호'}\n"
     ]
    }
   ],
   "source": [
    "print(datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7903681c-5ef3-4bcb-bb47-ade91c9992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # 오디오 데이터를 로드하고 48kHz에서 16kHz로 리샘플링\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # 입력 오디오 배열에서 log-Mel 입력 특징 계산\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # 타겟 텍스트를 레이블 ID로 인코딩\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3bb5f5-47dc-4b08-97e4-7c834d1cd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 원인\n",
    "\n",
    "# Whisper 모델: 16,000 Hz (16kHz) 샘플링 레이트로 학습됨\n",
    "# 현재 오디오 데이터: 24,000 Hz (24kHz)로 되어 있음\n",
    "\n",
    "# Google TTS로 생성한 오디오가 24kHz로 되어 있어서, Whisper가 요구하는 16kHz와 맞지 않습니다.\n",
    "\n",
    "# 데이터셋 로드 시 자동으로 16kHz로 리샘플링\n",
    "datasets = datasets.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# 그 다음 prepare_dataset 실행\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    # 이미 16kHz로 리샘플링되어 있음\n",
    "    batch[\"input_features\"] = feature_extractor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=16000  # 명시적으로 16000 사용\n",
    "    ).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "datasets = datasets.map(\n",
    "    prepare_dataset, \n",
    "    remove_columns=datasets.column_names[\"train\"], \n",
    "    num_proc=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923343c7-75d6-4ff1-8bfd-7d3b80964ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 중...\n",
      "trainable params: 13,107,200 || all params: 821,985,280 || trainable%: 1.5946\n"
     ]
    }
   ],
   "source": [
    "print(\"모델 로드 중...\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,  # gradient checkpointing과 호환되도록 설정\n",
    ")\n",
    "\n",
    "# 한국어 설정\n",
    "model.generation_config.language = \"ko\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "# 2. LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# 3. LoRA 모델로 변환\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 4. 학습 가능한 파라미터 확인\n",
    "model.print_trainable_parameters()\n",
    "# gradient checkpointing 명시적 비활성화 (LoRA와 충돌 방지)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c309c3b-6cab-42ed-bb1f-9dfdc581a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 입력과 레이블은 길이가 다르고 서로 다른 패딩 방법이 필요하므로 분리하여 처리\n",
    "        # 먼저 오디오 입력을 torch 텐서로 반환하여 처리\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 토크나이징된 레이블 시퀀스 가져오기\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # 레이블을 최대 길이에 맞춰 패딩\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 손실 계산 시 패딩을 올바르게 무시하도록 패딩 부분을 -100으로 교체\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 이전 토크나이징 단계에서 BOS 토큰이 추가된 경우,\n",
    "        # 나중에 어차피 추가되므로 여기서는 BOS 토큰 제거\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb545ac3-e6e8-4252-bf6e-e7cdf0c95175",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "563f16b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 배치 구조 ===\n",
      "input_features 크기: torch.Size([2, 128, 3000])\n",
      "labels 크기: torch.Size([2, 30])\n",
      "\n",
      "=== 첫 번째 샘플의 레이블 (처음 20개 토큰) ===\n",
      "tensor([50264, 50360, 50364,  2393, 15580,  5963,   117, 37604,  3833, 11958,\n",
      "        36912, 30600,  7675,  1457,   243,  7675,  6170, 12888,  7668,    21])\n",
      "\n",
      "=== 두 번째 샘플의 레이블 (처음 20개 토큰) ===\n",
      "tensor([50264, 50360, 50364,  2393, 15580,  5963,   117, 37604,  3833, 36074,\n",
      "         8097, 11545,  9520,  1831,  6826, 16270,  5254, 15390, 12504,  4264])\n",
      "\n",
      "=== 패딩 확인 (레이블의 마지막 10개 토큰) ===\n",
      "첫 번째 샘플: tensor([21483,   167, 33067, 11871,    18, 23056,  3446, 14060, 14705, 50257])\n",
      "두 번째 샘플: tensor([ 1129, 22452,    17, 23056,    19,  5211,    24, 14705, 50257,  -100])\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 위해 2개의 샘플 준비 (전처리된 데이터에서)\n",
    "sample_features = [\n",
    "    datasets[\"train\"][0],  # 첫 번째 샘플\n",
    "    datasets[\"train\"][1],  # 두 번째 샘플\n",
    "]\n",
    "\n",
    "# 콜레이터 적용\n",
    "batch = data_collator(sample_features)\n",
    "\n",
    "print(\"=== 배치 구조 ===\")\n",
    "print(f\"input_features 크기: {batch['input_features'].shape}\")\n",
    "print(f\"labels 크기: {batch['labels'].shape}\")\n",
    "\n",
    "print(\"\\n=== 첫 번째 샘플의 레이블 (처음 20개 토큰) ===\")\n",
    "print(batch['labels'][0][:20])\n",
    "\n",
    "print(\"\\n=== 두 번째 샘플의 레이블 (처음 20개 토큰) ===\")\n",
    "print(batch['labels'][1][:20])\n",
    "\n",
    "print(\"\\n=== 패딩 확인 (레이블의 마지막 10개 토큰) ===\")\n",
    "print(f\"첫 번째 샘플: {batch['labels'][0][-10:]}\")\n",
    "print(f\"두 번째 샘플: {batch['labels'][1][-10:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45225988-72c6-4034-b3be-4370aaeeb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 메트릭 (WER + CER)\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # -100을 pad_token_id로 교체\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # 디코딩\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # WER 계산\n",
    "    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    # CER 계산 (한국어에 특히 유용)\n",
    "    cer = 100 * cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    # 간단한 문자 정확도 (한국어용)\n",
    "    char_acc = calculate_korean_char_accuracy(pred_str, label_str)\n",
    "    \n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "        \"char_accuracy\": char_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4742c78-f3a8-4341-bc71-74690a40b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_korean_char_accuracy(predictions, references):\n",
    "    \"\"\"한국어 문자 단위 정확도 계산\"\"\"\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # 공백 제거 (한국어 띄어쓰기 오류 영향 최소화)\n",
    "        pred_chars = list(pred.replace(\" \", \"\"))\n",
    "        ref_chars = list(ref.replace(\" \", \"\"))\n",
    "        \n",
    "        # 최소 길이까지 비교\n",
    "        min_len = min(len(pred_chars), len(ref_chars))\n",
    "        for i in range(min_len):\n",
    "            if i < len(pred_chars) and pred_chars[i] == ref_chars[i]:\n",
    "                correct_chars += 1\n",
    "        \n",
    "        total_chars += len(ref_chars)\n",
    "    \n",
    "    return (correct_chars / total_chars * 100) if total_chars > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7c85fa-76b4-49e4-9a6e-709ce19c4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"./model-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "560f603d-a774-4461-989c-b27ef2bcac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    max_steps=100,\n",
    "    fp16=True,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    generation_max_length=256,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=5,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    predict_with_generate=True,\n",
    "    metric_for_best_model=\"cer\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a327d266-a25c-400e-9372-6be2fdb71c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32862/2306319984.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8c73164-5c75-48fe-84db-604db12a68fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 38:36, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Char Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.323696</td>\n",
       "      <td>26.176471</td>\n",
       "      <td>2.534609</td>\n",
       "      <td>95.265711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.055290</td>\n",
       "      <td>11.176471</td>\n",
       "      <td>0.926303</td>\n",
       "      <td>98.797976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>0.346091</td>\n",
       "      <td>99.283003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>2.058824</td>\n",
       "      <td>0.203583</td>\n",
       "      <td>99.620413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.050896</td>\n",
       "      <td>99.947280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.030537</td>\n",
       "      <td>99.968368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>99.978912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>99.978912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>99.978912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>99.978912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.08768495686352253, metrics={'train_runtime': 2332.1134, 'train_samples_per_second': 2.744, 'train_steps_per_second': 0.043, 'total_flos': 1.100779249729536e+19, 'train_loss': 0.08768495686352253, 'epoch': 1.8598130841121496})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157ba42-c2f0-4e3a-b064-2319d871efb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
