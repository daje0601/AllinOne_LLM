{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvl-kct_HpS"
      },
      "source": [
        "## 2.1 Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftOlXRwN-VNI",
        "outputId": "7fd3f412-731d-4228-e8c1-c75a4443d4ab"
      },
      "outputs": [],
      "source": [
        "%pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "ec93ee137c744ff5b295279725e09a65",
            "8ab5d4e79ddd4970b0742b0564778686",
            "fc50de167cbb4854889b30566865880a",
            "d278405519a345e8bada2f7a25202a84",
            "46d4253ab0f94e81bfaef37affc34dfd",
            "3e708fe68d4540c3974e7e6eaa5e8cbd",
            "c5cdf82c6d8040f4b07b8c619446b1bd",
            "a2ad2c69c700496ab321dfabe6341c9d",
            "ad5a7b684ae348e38f14ef7aa493879e",
            "433d7aa716884ab2848a056d609c13eb",
            "dcdd98a2fa7644e08957fc6f5f96d113",
            "7effcd85ab3b4605aed86914287581a8",
            "2c3627fa3f6f4c10a75078e97268de2a",
            "de2c259a00b44b6e9a7e2d361d9d9e58",
            "7e9c1dc8ce5542b4b6d5954be3c7a27d",
            "390d95fb9b764cb386d4f035bd7707f5",
            "002801e955c04be0924475836b728db4",
            "39f349fb1bef4ba1989957c947ed2790",
            "ed3db20274a147ec8b2f56cbe4c44244",
            "eb0b0a65dc2e46bab6edd9acb3904654",
            "29f8266f139a476c9ba8384fbc95e687",
            "023c222250b54303ba1341aecc36a5e2",
            "ea1468f0a5ce46eeaf507487e91b9b11",
            "03897cad397d4655ac7b861e9c19dee1",
            "ecb3603858524661a91d9fc987953c39",
            "e2e8a930e0564536b660514d7b7eac3d",
            "99b5f7bf1c75411d91d2c38b5a5f1650",
            "2e89c5637ef64cd7996c534b03ff6b89",
            "0d99bfb9212b4e909dbb4b573fe0a2d0",
            "c1552547ae184d9c90e3f9adc075357f",
            "75496aa46f19418fb0732ecd8b1ba80a",
            "5d3c1cec507d4415886a3b0a4af775a3",
            "939d623b4da5443690580ecced914d39",
            "0d2aefa9c6ac40488716b65f36e2f91a",
            "b84b294a22c24d1593c43b595fcc01c1",
            "09c619506ef94deab33b5098fc9b506e",
            "765cdd647fde4879a0c0b4b7781633e7",
            "8af4ac61a1174fa49502cecd2096e401",
            "040730011bb74777af4f858cb577f2da",
            "cc2d95134dcc4f0d94d7b858005249a5",
            "a6c0c8b2286449ca8fd45c95f4ecbdfa",
            "e16164e7707e44288cc3d9f28256e8f3",
            "de58492a1c9d4e21a262c75be725d4e8",
            "9994975564e742998e20f971d9b6eee8",
            "ec9e4ee2320949e980d0c9b47b7d8bec",
            "55c167c94da146b980a95dadb6c77ba2",
            "1b861cb41a1547b6a11be44efd2e5793",
            "387066acc3e14c459c783c2d391ff53c",
            "4a3451e5a86040c0bca239e854ab5e72",
            "d9d0e5cf32244ae981f9caa4eb6ed88d",
            "95fb2560b1f54205b5d891066aed4abe",
            "7fbb7e94a5bc488babad4f65cf34a963",
            "87cd6e6ee87a4a06af08b2c118de4cc4",
            "ffabb993911246deaeb93c5ff88b8a96",
            "ab3e4268422b4dd3bfcb33961a15db4d",
            "1bf81aa1906047aebf3608453e18b07c",
            "3a84a89b63104f95828c4218518b0145",
            "e39694878b4a4130afc64964ba3802fb",
            "38baf2941a684e5a936cce69e7066737",
            "0d0a684806344eab83b04946e0a3a5ce",
            "47011a02d27b4036b189969334648276",
            "cfbe419d57f24847abd4ec7a6a10e538",
            "8847b615e5ef4cf6b1faed7fa75a198c",
            "d92a75df50404ae5a515c882df326ea2",
            "4977026032ef4441ae29b053c6eae6f3",
            "45e03e4d771848759fda994678a0a37e",
            "48ded80b7fbe47ed8101b37655c0f3b0",
            "4184e9d862fd4c23adf60c411a8367d4",
            "efaa726bfda64745a4e31d01dccd2e36",
            "4682c9221fad474c8d4ca65208db4a5d",
            "d17d733af9b84f209abbff4d595ab6dd",
            "0c8627e500a348e5add600d89320b988",
            "c0f8375098c843d49350af1411d4105b",
            "6e1965c4a89a4679b17ebdf3e15cf372",
            "ca302496343646c8ba648fdbed76ec31",
            "0933a953140a4839865830dedda6be4b",
            "dc2cf200389c431f88102243b0fb0032"
          ]
        },
        "id": "cTFQu3TvaTxD",
        "outputId": "7bc35aeb-1bce-4f97-e643-cefd74832315"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rHLpiIT-o0z",
        "outputId": "4d610e55-825e-47d0-fd25-c8f15710f9be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 22194\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2466\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2740\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = dataset\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "_ZXENG-h-9uE",
        "outputId": "11f81e0b-2b2b-416f-a1a4-506adcb86a64"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'앵커 정부가 올해 하반기 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 했습니다. 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했습니다. 류환홍 기자가 보도합니다. 기자 수출은 최고의 실적을 보였지만 수입액이 급증하면서 올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록했습니다. 정부가 수출확대에 총력을 기울이기로 한 것은 원자재 가격 상승 등 대외 리스크가 가중되는 상황에서 수출 증가세 지속이야말로 한국경제의 회복을 위한 열쇠라고 본 것입니다. 추경호 경제부총리 겸 기획재정부 장관 정부는 우리 경제의 성장엔진인 수출이 높은 증가세를 지속할 수 있도록 총력을 다하겠습니다. 우선 물류 부담 증가 원자재 가격 상승 등 가중되고 있는 대외 리스크에 대해 적극 대응하겠습니다. 특히 중소기업과 중견기업 수출 지원을 위해 무역금융 규모를 연초 목표보다 40조 원 늘린 301조 원까지 확대하고 물류비 부담을 줄이기 위한 대책도 마련했습니다. 이창양 산업통상자원부 장관 국제 해상운임이 안정될 때까지 월 4척 이상의 임시선박을 지속 투입하는 한편 중소기업 전용 선복 적재 용량 도 현재보다 주당 50TEU 늘려 공급하겠습니다. 하반기에 우리 기업들의 수출 기회를 늘리기 위해 2 500여 개 수출기업을 대상으로 해외 전시회 참가를 지원하는 등 마케팅 지원도 벌이기로 했습니다. 정부는 또 이달 중으로 반도체를 비롯한 첨단 산업 육성 전략을 마련해 수출 증가세를 뒷받침하고 에너지 소비를 줄이기 위한 효율화 방안을 마련해 무역수지 개선에 나서기로 했습니다. YTN 류환홍입니다.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"train\"][\"document\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qLL0P-j_Mv6",
        "outputId": "cfb6a35a-7381-4cfe-c058-ed05ac3ed4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[' ', '.', '0', '1', '2', '3', '4', '5', 'E', 'N', 'T', 'U', 'Y', '가', '개', '것', '겠', '격', '견', '겸', '경', '고', '공', '과', '관', '국', '규', '극', '금', '급', '기', '까', '나', '난', '너', '높', '는', '늘', '니', '다', '단', '달', '담', '당', '대', '도', '되', '될', '뒷', '들', '등', '때', '또', '라', '략', '량', '러', '려', '력', '련', '로', '록', '롯', '류', '를', '리', '린', '마', '만', '말', '면', '모', '목', '무', '물', '박', '반', '받', '방', '버', '벌', '보', '복', '본', '부', '비', '산', '상', '서', '선', '성', '세', '소', '속', '쇠', '수', '스', '습', '승', '시', '실', '악', '안', '액', '앵', '야', '양', '억', '업', '에', '엔', '여', '역', '연', '열', '였', '올', '외', '용', '우', '운', '울', '원', '월', '위', '육', '율', '융', '으', '은', '을', '응', '의', '이', '인', '임', '입', '있', '자', '장', '재', '적', '전', '정', '제', '조', '주', '줄', '중', '증', '지', '진', '참', '창', '책', '척', '첨', '체', '초', '총', '최', '추', '출', '침', '커', '케', '크', '통', '투', '특', '팀', '팅', '편', '표', '하', '한', '할', '합', '해', '했', '현', '호', '홍', '화', '확', '환', '황', '회', '획', '효', '히']\n"
          ]
        }
      ],
      "source": [
        "print(sorted(list(set(data[\"train\"][\"document\"][0]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GYMH9-GiNX",
        "outputId": "53712bf7-d86d-4995-f84a-328a31835909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 글자 수 : 2701\n"
          ]
        }
      ],
      "source": [
        "# 이것은 텍스트에 나타나는 모든 문자 집합을 가져온 것입니다.\n",
        "# 그것들은 고유한 것들만 남겨서 sorted로 정렬을 하면 아래와 같은 결과를 볼 수 있습니다.\n",
        "ko_text = \"\".join(data[\"train\"][\"document\"])\n",
        "ko_chars = sorted(list(set((ko_text))))\n",
        "ko_vocab_size = len(ko_chars)\n",
        "print(\"총 글자 수 :\", ko_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKbhxV4vAmOQ",
        "outputId": "305dbb00-87d6-42ad-ff9c-84db282d5ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['왓', '왔', '왕', '왜', '왠', '외', '왹', '왼', '요', '욕', '욘', '욜', '욤', '욥', '용', '우', '욱', '운', '욷', '울', '움', '웁', '웃', '웅', '워', '웍', '원', '월', '웜', '웠', '웡', '웨', '웬', '웰', '웸', '웹', '웻', '위', '윅', '윈', '윌', '윔', '윕', '윗', '윙', '유', '육', '윤', '율', '윱', '윳', '융', '으', '윽', '은', '을', '음', '읍', '읏', '응', '의', '읠', '이', '익', '인', '일', '읽', '잃', '임', '입', '잇', '있', '잉', '잊', '잎', '자', '작', '잔', '잖', '잘', '잠', '잡', '잣', '잤', '장', '잦', '재', '잭', '잰', '잼', '잽', '잿', '쟁', '쟈', '쟝', '쟤', '저', '적', '전', '절']\n"
          ]
        }
      ],
      "source": [
        "print(ko_chars[2000:2100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ETFPhxIQHB",
        "outputId": "ab21bd34-f5c9-424b-d4d9-6f2833d9cdd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1909, 1169, 2546, 1770, 2008, 0, 2551, 1061, 0, 2064, 977, 2157, 1209, 2055, 0, 977, 1658, 2546, 949, 0, 1283, 1942, 0, 1593, 908, 2024, 2008, 2]\n",
            "안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\n"
          ]
        }
      ],
      "source": [
        "character_to_ids = {char:i for i, char in enumerate(ko_chars)}\n",
        "ids_to_character = {i:char for i, char in enumerate(ko_chars)}\n",
        "token_encode = lambda s:[character_to_ids[c] for c in s]\n",
        "token_decode = lambda l: \"\".join([ids_to_character[i] for i in l])\n",
        "print(token_encode(\"안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\"))\n",
        "print(token_decode(token_encode(\"안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W87I2kYcTCy2",
        "outputId": "b30cffb4-db6a-4fd5-94af-ed983917ecb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([22162967]) torch.int64\n",
            "tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987, 2555,    0, 2546, 1593,\n",
            "        1028,    0, 2015, 1485,    0,  965, 2107, 2060,    0, 1617, 2465, 1542,\n",
            "        2064,    0, 1808, 2273,    0, 2603, 1236, 1477,    0, 2037, 2555,    0,\n",
            "        2263, 1430, 2055,    0, 1028, 2019, 2062, 1028, 1441,    0, 2562, 1841,\n",
            "        1213, 1221,    2,    0, 2451, 2650,    0, 1808, 2273,    0, 2142, 1787,\n",
            "        1028, 1950, 2060,    0, 1558, 1468, 1119,    0, 2555, 1787, 1477,    0,\n",
            "        2037, 2555,    0, 1553, 1967, 1024, 2051,    0, 1015, 1541, 1477,    0,\n",
            "           7,    3, 2117,    0, 2026,    0, 2062, 1740,    0, 2603, 1236, 2546,\n",
            "         968,    0, 1558, 1468])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "tokenized_data = torch.tensor(token_encode(ko_text), dtype=torch.long)\n",
        "print(tokenized_data.shape, tokenized_data.dtype)\n",
        "print(tokenized_data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ageww9dKV5Rj"
      },
      "outputs": [],
      "source": [
        "#이제 본격적으로 코드를 작성하기에 앞서서 train_data와 val_data로 나누는 작업을 진행하겠습니다.\n",
        "\n",
        "n = int(0.9 * len(tokenized_data))\n",
        "train_dataset = tokenized_data[:n]\n",
        "test_dataset = tokenized_data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWZQp1i-H59n",
        "outputId": "5875d443-a1f6-4257-f176-8287d7492ee7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_dataset[:block_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ko20BmaIArc",
        "outputId": "4ce0d887-f99b-4699-f225-3045a18f0f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 텐셔 : tensor([1928])\n",
            "타켓 글자 : 2315\n",
            "입력 텐셔 : tensor([1928, 2315])\n",
            "타켓 글자 : 0\n",
            "입력 텐셔 : tensor([1928, 2315,    0])\n",
            "타켓 글자 : 2105\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105])\n",
            "타켓 글자 : 1658\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658])\n",
            "타켓 글자 : 908\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658,  908])\n",
            "타켓 글자 : 0\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658,  908,    0])\n",
            "타켓 글자 : 1987\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987])\n",
            "타켓 글자 : 2555\n"
          ]
        }
      ],
      "source": [
        "x = train_dataset[:block_size]\n",
        "y = train_dataset[1:block_size+1]\n",
        "\n",
        "for time in range(block_size):\n",
        "    context = x[:time+1]\n",
        "    target = y[time]\n",
        "\n",
        "    print(f\"입력 텐셔 : {context}\")\n",
        "    print(f\"타켓 글자 : {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsUIhDG4M4AL",
        "outputId": "3e8a6608-f97d-4c4c-927f-e6a83d7579a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs :  torch.Size([4, 8])\n",
            "\n",
            "example_x의 실제 값\n",
            "tensor([[1764, 2555,    0, 1236, 2248,    0, 2017, 1976],\n",
            "        [   0, 1966, 2157,    0, 1951, 2062,    0, 2548],\n",
            "        [   0, 1304, 1485, 1586,    0, 1907, 2450,    0],\n",
            "        [   3,    2,    6,    5,    1,    0,    5,    3]])\n",
            "-----------------------\n",
            "targets :  torch.Size([4, 8])\n",
            "\n",
            "example_y의 실제 값\n",
            "tensor([[2555,    0, 1236, 2248,    0, 2017, 1976, 2546],\n",
            "        [1966, 2157,    0, 1951, 2062,    0, 2548, 2289],\n",
            "        [1304, 1485, 1586,    0, 1907, 2450,    0, 2480],\n",
            "        [   2,    6,    5,    1,    0,    5,    3,    5]])\n",
            "-----------------------\n",
            "input : tensor([1764]), target : 2555\n",
            "input : tensor([1764, 2555]), target : 0\n",
            "input : tensor([1764, 2555,    0]), target : 1236\n",
            "input : tensor([1764, 2555,    0, 1236]), target : 2248\n",
            "input : tensor([1764, 2555,    0, 1236, 2248]), target : 0\n",
            "input : tensor([1764, 2555,    0, 1236, 2248,    0]), target : 2017\n",
            "input : tensor([1764, 2555,    0, 1236, 2248,    0, 2017]), target : 1976\n",
            "input : tensor([1764, 2555,    0, 1236, 2248,    0, 2017, 1976]), target : 2546\n",
            "-----------------------\n",
            "-----------------------\n",
            "input : tensor([0]), target : 1966\n",
            "input : tensor([   0, 1966]), target : 2157\n",
            "input : tensor([   0, 1966, 2157]), target : 0\n",
            "input : tensor([   0, 1966, 2157,    0]), target : 1951\n",
            "input : tensor([   0, 1966, 2157,    0, 1951]), target : 2062\n",
            "input : tensor([   0, 1966, 2157,    0, 1951, 2062]), target : 0\n",
            "input : tensor([   0, 1966, 2157,    0, 1951, 2062,    0]), target : 2548\n",
            "input : tensor([   0, 1966, 2157,    0, 1951, 2062,    0, 2548]), target : 2289\n",
            "-----------------------\n",
            "-----------------------\n",
            "input : tensor([0]), target : 1304\n",
            "input : tensor([   0, 1304]), target : 1485\n",
            "input : tensor([   0, 1304, 1485]), target : 1586\n",
            "input : tensor([   0, 1304, 1485, 1586]), target : 0\n",
            "input : tensor([   0, 1304, 1485, 1586,    0]), target : 1907\n",
            "input : tensor([   0, 1304, 1485, 1586,    0, 1907]), target : 2450\n",
            "input : tensor([   0, 1304, 1485, 1586,    0, 1907, 2450]), target : 0\n",
            "input : tensor([   0, 1304, 1485, 1586,    0, 1907, 2450,    0]), target : 2480\n",
            "-----------------------\n",
            "-----------------------\n",
            "input : tensor([3]), target : 2\n",
            "input : tensor([3, 2]), target : 6\n",
            "input : tensor([3, 2, 6]), target : 5\n",
            "input : tensor([3, 2, 6, 5]), target : 1\n",
            "input : tensor([3, 2, 6, 5, 1]), target : 0\n",
            "input : tensor([3, 2, 6, 5, 1, 0]), target : 5\n",
            "input : tensor([3, 2, 6, 5, 1, 0, 5]), target : 3\n",
            "input : tensor([3, 2, 6, 5, 1, 0, 5, 3]), target : 5\n",
            "-----------------------\n",
            "-----------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1234)\n",
        "\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    return x, y\n",
        "\n",
        "example_x, example_y = batch_function(\"train\")\n",
        "print(\"inputs : \", example_x.shape)\n",
        "print(\"\")\n",
        "print(\"example_x의 실제 값\")\n",
        "print(example_x)\n",
        "print(\"-----------------------\")\n",
        "print(\"targets : \", example_y.shape)\n",
        "print(\"\")\n",
        "print(\"example_y의 실제 값\")\n",
        "print(example_y)\n",
        "print(\"-----------------------\")\n",
        "\n",
        "for size in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = example_x[size, :t+1]\n",
        "        target = example_y[size, t]\n",
        "        print(f\"input : {context}, target : {target}\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"-----------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRBfQUkdbLMl",
        "outputId": "ac31df03-b89d-4761-fd8c-05e3f49fd244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2701,\n",
              " torch.Size([4, 8]),\n",
              " tensor([[2555,    0, 1236, 2248,    0, 2017, 1976, 2546],\n",
              "         [1966, 2157,    0, 1951, 2062,    0, 2548, 2289],\n",
              "         [1304, 1485, 1586,    0, 1907, 2450,    0, 2480],\n",
              "         [   2,    6,    5,    1,    0,    5,    3,    5]]))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ko_vocab_size, example_x.shape, example_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3 언어모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3.1 ~ 2.3.2 라이브러리 설명 & _ _ init _ _ 함수 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfTlxhxvPvPz",
        "outputId": "8281eb29-cac7-4529-a02a-9c302b8542fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8, 2701])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = semiGPT(ko_vocab_size)\n",
        "output = model(example_x, example_y)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "3q-qrQmJqs4Y",
        "outputId": "dc47edd4-0558-47dc-97ba-376b9e999cba"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-cdf876adb83c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#에러가 발생되도록 설정한 코드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "#에러가 발생되도록 설정한 코드\n",
        "embedding = nn.Embedding(4, 4)\n",
        "embedding(torch.tensor([[0, 1, 2, 10]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Pd48zq7q4YnG",
        "outputId": "8a039af9-49e5-4f5f-8641-271445159548"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected target size [4, 2701], got [4, 8]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-ee5a1ffe9b4a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemi_GPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mko_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-ee5a1ffe9b4a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_token_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [4, 2701], got [4, 8]"
          ]
        }
      ],
      "source": [
        "#에러가 발생되도록 세팅된 코드\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "model = semiGPT(ko_vocab_size)\n",
        "output, loss = model(example_x, example_y)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3.3 forward 메서드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA-jQJr8vITi",
        "outputId": "58abb19d-c2d7-4a05-aff0-3cb4bfe73140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits의 shape는 :  torch.Size([32, 2701]) 입니다.\n",
            "targets의 shape는 :  torch.Size([32]) 입니다.\n",
            "tensor(8.2693, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        batch, seq_length, vocab_length = logits.shape\n",
        "        logits = logits.view(batch * seq_length, vocab_length)\n",
        "        targets = targets.view(batch*seq_length)\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        print(\"logits의 shape는 : \", logits.shape, \"입니다.\")\n",
        "        print(\"targets의 shape는 : \", targets.shape, \"입니다.\")\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "model = semiGPT(ko_vocab_size)\n",
        "logits, loss = model(example_x, example_y)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VzaAIhukiYM",
        "outputId": "18f8d63b-c70d-4dd6-c81f-ef246e069e6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 8]), torch.Size([4, 8]))"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_x.shape, example_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3.4 generate 메서드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "WkygPqh48BEr",
        "outputId": "2811f68d-f4da-4333-8bcc-ab5fd7bd3643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.5209, grad_fn=<NllLossBackward0>)\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 엿입拓빤쌩슝찮찡펭屬'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "            targets = targets.view(batch*seq_length)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(inputs)\n",
        "            logits = logits[:, -1, :]\n",
        "            print(logits.shape)\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "model = semiGPT(ko_vocab_size)\n",
        "logits, loss = model(example_x, example_y)\n",
        "print(loss)\n",
        "\n",
        "token_decode(model.generate(torch.zeros((1,1),\n",
        "                                        dtype=torch.long),\n",
        "                            max_new_tokens=10)[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FGEiDtY5Xm6",
        "outputId": "3371cb6b-d717-4eb1-fe46-ea7a12d9b9c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "선택되는 값        :  tensor([[0.3000, 0.4000, 0.1000, 0.2000]])\n",
            "결과에 대한 size 값 :  torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "logits = torch.tensor(\n",
        "    [\n",
        "        [\n",
        "            [0.1, 0.2, 0.3, 0.4],\n",
        "            [0.2, 0.3, 0.4, 0.1],\n",
        "            [0.3, 0.4, 0.1, 0.2]\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "\n",
        "result = logits[:,-1,:]\n",
        "print(\"선택되는 값        : \", result)\n",
        "print(\"결과에 대한 size 값 : \", result.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 optimizer 추가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "5pUA0PzoBbBR"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-2\n",
        "model = semiGPT(ko_vocab_size)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9425dffaabf94380bea9bcd7b0f0fa70",
            "0bb7a4769b634f47b8a583f3e9ccc850",
            "7d03ae6fe1734f67be4d6e853344f4a0",
            "07473a41fe4f4509ab2f568848d825a3",
            "2e9b839cecf74c72aca3cca09315ad1b",
            "61082149f78f4eb68881ccc883f18871",
            "14caabc3d225443d86aa8d31ebab9c7a",
            "aecbfaad9e3a4b688280bc2669103452",
            "b7c864c69cc34a79bba2cb69e43ccba6",
            "b657d36f98da461292f697d1fcb5d4e3",
            "53e1dc6bcaf540f8817117c70367d82e"
          ]
        },
        "id": "iSIFexR7JuwY",
        "outputId": "7bdaa3e4-127d-418e-82e7-80c1a3e0ccfc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9425dffaabf94380bea9bcd7b0f0fa70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.477691411972046\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "batch_size = 32\n",
        "for steps in tqdm(range(10000)):\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    # 옵티마이저 초기화 \n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    # 역전파 계산 \n",
        "    loss.backward()\n",
        "    # 가중치 업데이트 \n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScmQ3IOfQjJs",
        "outputId": "36427900-c394-4b04-8f4c-d4fb0ce57129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            " 협력에 오를 것이 \n"
          ]
        }
      ],
      "source": [
        "print(token_decode(model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=10)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zYfTMmrh5a"
      },
      "source": [
        "### 2.4.1 GPU로 데이터를 옮기는 방법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm_CQc8Jr8Hn"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4.2 Loss 함수 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1hbgq5gr-85"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4.3 전체 코드 복습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* 책에는 for문부터 설명이 나와있지만, 실행하는데 햇갈리실거 같아 코드는 전체 코드를 기록해놓았습니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUSTcPJvaglZ",
        "outputId": "28802d42-5b8f-4726-9b05-48c513b02f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 8.3225, val loss : 8.3266\n",
            "step : 300, train loss : 6.0857, val loss : 6.0748\n",
            "step : 600, train loss : 4.7943, val loss : 4.7822\n",
            "step : 900, train loss : 4.2353, val loss : 4.2261\n",
            "step : 1200, train loss : 3.9576, val loss : 3.9557\n",
            "step : 1500, train loss : 3.8215, val loss : 3.8180\n",
            "step : 1800, train loss : 3.7062, val loss : 3.7000\n",
            "step : 2100, train loss : 3.6504, val loss : 3.6657\n",
            "step : 2400, train loss : 3.6248, val loss : 3.6283\n",
            "step : 2700, train loss : 3.5896, val loss : 3.5865\n",
            "step : 3000, train loss : 3.5797, val loss : 3.5695\n",
            "step : 3300, train loss : 3.5399, val loss : 3.5308\n",
            "step : 3600, train loss : 3.5256, val loss : 3.5289\n",
            "step : 3900, train loss : 3.5061, val loss : 3.5127\n",
            "step : 4200, train loss : 3.4900, val loss : 3.4989\n",
            "step : 4500, train loss : 3.4810, val loss : 3.4903\n",
            "step : 4800, train loss : 3.4961, val loss : 3.4815\n",
            "step : 5100, train loss : 3.4668, val loss : 3.4674\n",
            "step : 5400, train loss : 3.4622, val loss : 3.4567\n",
            "step : 5700, train loss : 3.4577, val loss : 3.4347\n",
            "step : 6000, train loss : 3.4475, val loss : 3.4602\n",
            "step : 6300, train loss : 3.4473, val loss : 3.4574\n",
            "step : 6600, train loss : 3.4352, val loss : 3.4373\n",
            "step : 6900, train loss : 3.4309, val loss : 3.4421\n",
            "step : 7200, train loss : 3.4287, val loss : 3.4301\n",
            "step : 7500, train loss : 3.4324, val loss : 3.4579\n",
            "step : 7800, train loss : 3.4104, val loss : 3.4247\n",
            "step : 8100, train loss : 3.4229, val loss : 3.4418\n",
            "step : 8400, train loss : 3.4243, val loss : 3.4259\n",
            "step : 8700, train loss : 3.4164, val loss : 3.4423\n",
            "step : 9000, train loss : 3.4150, val loss : 3.4207\n",
            "step : 9300, train loss : 3.4119, val loss : 3.4390\n",
            "step : 9600, train loss : 3.4094, val loss : 3.4277\n",
            "step : 9900, train loss : 3.4059, val loss : 3.4122\n",
            "step : 10200, train loss : 3.4005, val loss : 3.4280\n",
            "step : 10500, train loss : 3.4216, val loss : 3.4124\n",
            "step : 10800, train loss : 3.4111, val loss : 3.3984\n",
            "step : 11100, train loss : 3.3956, val loss : 3.4139\n",
            "step : 11400, train loss : 3.4072, val loss : 3.4189\n",
            "step : 11700, train loss : 3.3945, val loss : 3.4112\n",
            "step : 12000, train loss : 3.4020, val loss : 3.4050\n",
            "step : 12300, train loss : 3.3896, val loss : 3.4233\n",
            "step : 12600, train loss : 3.4181, val loss : 3.4056\n",
            "step : 12900, train loss : 3.3971, val loss : 3.4386\n",
            "step : 13200, train loss : 3.3891, val loss : 3.4215\n",
            "step : 13500, train loss : 3.4137, val loss : 3.4053\n",
            "step : 13800, train loss : 3.4119, val loss : 3.4067\n",
            "step : 14100, train loss : 3.3843, val loss : 3.4066\n",
            "step : 14400, train loss : 3.3990, val loss : 3.4154\n",
            "step : 14700, train loss : 3.3997, val loss : 3.3927\n",
            "step : 15000, train loss : 3.4050, val loss : 3.4046\n",
            "step : 15300, train loss : 3.4123, val loss : 3.4050\n",
            "step : 15600, train loss : 3.3921, val loss : 3.4022\n",
            "step : 15900, train loss : 3.3763, val loss : 3.4093\n",
            "step : 16200, train loss : 3.3893, val loss : 3.4076\n",
            "step : 16500, train loss : 3.3917, val loss : 3.4088\n",
            "step : 16800, train loss : 3.3741, val loss : 3.4048\n",
            "step : 17100, train loss : 3.4035, val loss : 3.4035\n",
            "step : 17400, train loss : 3.3919, val loss : 3.4066\n",
            "step : 17700, train loss : 3.3967, val loss : 3.4217\n",
            "step : 18000, train loss : 3.4046, val loss : 3.4072\n",
            "step : 18300, train loss : 3.3936, val loss : 3.3961\n",
            "step : 18600, train loss : 3.4019, val loss : 3.4033\n",
            "step : 18900, train loss : 3.3883, val loss : 3.3921\n",
            "step : 19200, train loss : 3.3879, val loss : 3.4024\n",
            "step : 19500, train loss : 3.4085, val loss : 3.3852\n",
            "step : 19800, train loss : 3.3859, val loss : 3.4168\n",
            "step : 20100, train loss : 3.3847, val loss : 3.3994\n",
            "step : 20400, train loss : 3.3986, val loss : 3.3968\n",
            "step : 20700, train loss : 3.4036, val loss : 3.3823\n",
            "step : 21000, train loss : 3.3902, val loss : 3.4039\n",
            "step : 21300, train loss : 3.4100, val loss : 3.4011\n",
            "step : 21600, train loss : 3.3894, val loss : 3.4053\n",
            "step : 21900, train loss : 3.3914, val loss : 3.3996\n",
            "step : 22200, train loss : 3.3829, val loss : 3.3966\n",
            "step : 22500, train loss : 3.3866, val loss : 3.4039\n",
            "step : 22800, train loss : 3.3990, val loss : 3.4039\n",
            "step : 23100, train loss : 3.3842, val loss : 3.4068\n",
            "step : 23400, train loss : 3.3760, val loss : 3.3969\n",
            "step : 23700, train loss : 3.3782, val loss : 3.4216\n",
            "step : 24000, train loss : 3.3898, val loss : 3.3935\n",
            "step : 24300, train loss : 3.4169, val loss : 3.4038\n",
            "step : 24600, train loss : 3.3884, val loss : 3.4087\n",
            "step : 24900, train loss : 3.3928, val loss : 3.4098\n",
            "step : 25200, train loss : 3.3888, val loss : 3.3915\n",
            "step : 25500, train loss : 3.3886, val loss : 3.4051\n",
            "step : 25800, train loss : 3.3919, val loss : 3.3864\n",
            "step : 26100, train loss : 3.3881, val loss : 3.3920\n",
            "step : 26400, train loss : 3.3826, val loss : 3.4092\n",
            "step : 26700, train loss : 3.3967, val loss : 3.3886\n",
            "step : 27000, train loss : 3.3870, val loss : 3.3932\n",
            "step : 27300, train loss : 3.3962, val loss : 3.3759\n",
            "step : 27600, train loss : 3.3891, val loss : 3.3985\n",
            "step : 27900, train loss : 3.3984, val loss : 3.4033\n",
            "step : 28200, train loss : 3.3905, val loss : 3.3880\n",
            "step : 28500, train loss : 3.4183, val loss : 3.3965\n",
            "step : 28800, train loss : 3.4027, val loss : 3.4066\n",
            "step : 29100, train loss : 3.3895, val loss : 3.3939\n",
            "step : 29400, train loss : 3.3825, val loss : 3.3862\n",
            "step : 29700, train loss : 3.4112, val loss : 3.4027\n",
            "step : 30000, train loss : 3.3942, val loss : 3.3920\n",
            "step : 30300, train loss : 3.3828, val loss : 3.3943\n",
            "step : 30600, train loss : 3.3920, val loss : 3.4067\n",
            "step : 30900, train loss : 3.3948, val loss : 3.4087\n",
            "step : 31200, train loss : 3.3844, val loss : 3.4096\n",
            "step : 31500, train loss : 3.3933, val loss : 3.4205\n",
            "step : 31800, train loss : 3.4029, val loss : 3.4084\n",
            "step : 32100, train loss : 3.3935, val loss : 3.4013\n",
            "step : 32400, train loss : 3.3924, val loss : 3.4080\n",
            "step : 32700, train loss : 3.3807, val loss : 3.3924\n",
            "step : 33000, train loss : 3.3964, val loss : 3.3883\n",
            "step : 33300, train loss : 3.3786, val loss : 3.4052\n",
            "step : 33600, train loss : 3.3803, val loss : 3.3966\n",
            "step : 33900, train loss : 3.3935, val loss : 3.3991\n",
            "step : 34200, train loss : 3.3900, val loss : 3.4211\n",
            "step : 34500, train loss : 3.3939, val loss : 3.3638\n",
            "step : 34800, train loss : 3.3991, val loss : 3.3896\n",
            "step : 35100, train loss : 3.3904, val loss : 3.4056\n",
            "step : 35400, train loss : 3.3950, val loss : 3.3941\n",
            "step : 35700, train loss : 3.3854, val loss : 3.4029\n",
            "step : 36000, train loss : 3.4060, val loss : 3.4110\n",
            "step : 36300, train loss : 3.3954, val loss : 3.3985\n",
            "step : 36600, train loss : 3.3893, val loss : 3.4049\n",
            "step : 36900, train loss : 3.3924, val loss : 3.4051\n",
            "step : 37200, train loss : 3.3962, val loss : 3.3976\n",
            "step : 37500, train loss : 3.3835, val loss : 3.3976\n",
            "step : 37800, train loss : 3.4046, val loss : 3.3920\n",
            "step : 38100, train loss : 3.3748, val loss : 3.4056\n",
            "step : 38400, train loss : 3.3828, val loss : 3.4183\n",
            "step : 38700, train loss : 3.3758, val loss : 3.4043\n",
            "step : 39000, train loss : 3.4111, val loss : 3.4036\n",
            "step : 39300, train loss : 3.4103, val loss : 3.4064\n",
            "step : 39600, train loss : 3.3878, val loss : 3.3929\n",
            "step : 39900, train loss : 3.4084, val loss : 3.3991\n",
            "step : 40200, train loss : 3.3983, val loss : 3.3928\n",
            "step : 40500, train loss : 3.3788, val loss : 3.3848\n",
            "step : 40800, train loss : 3.3994, val loss : 3.4057\n",
            "step : 41100, train loss : 3.3895, val loss : 3.4040\n",
            "step : 41400, train loss : 3.3935, val loss : 3.3901\n",
            "step : 41700, train loss : 3.3907, val loss : 3.4171\n",
            "step : 42000, train loss : 3.3896, val loss : 3.3983\n",
            "step : 42300, train loss : 3.3812, val loss : 3.4163\n",
            "step : 42600, train loss : 3.3707, val loss : 3.4115\n",
            "step : 42900, train loss : 3.3919, val loss : 3.4075\n",
            "step : 43200, train loss : 3.4001, val loss : 3.3959\n",
            "step : 43500, train loss : 3.4125, val loss : 3.3881\n",
            "step : 43800, train loss : 3.4025, val loss : 3.3983\n",
            "step : 44100, train loss : 3.3894, val loss : 3.4140\n",
            "step : 44400, train loss : 3.3989, val loss : 3.3933\n",
            "step : 44700, train loss : 3.3976, val loss : 3.3876\n",
            "step : 45000, train loss : 3.4052, val loss : 3.4118\n",
            "step : 45300, train loss : 3.3998, val loss : 3.3989\n",
            "step : 45600, train loss : 3.3879, val loss : 3.3953\n",
            "step : 45900, train loss : 3.3918, val loss : 3.3973\n",
            "step : 46200, train loss : 3.3971, val loss : 3.3930\n",
            "step : 46500, train loss : 3.3911, val loss : 3.4164\n",
            "step : 46800, train loss : 3.3901, val loss : 3.3963\n",
            "step : 47100, train loss : 3.4003, val loss : 3.3987\n",
            "step : 47400, train loss : 3.3802, val loss : 3.3944\n",
            "step : 47700, train loss : 3.4033, val loss : 3.4172\n",
            "step : 48000, train loss : 3.3846, val loss : 3.3995\n",
            "step : 48300, train loss : 3.3859, val loss : 3.4152\n",
            "step : 48600, train loss : 3.3926, val loss : 3.4012\n",
            "step : 48900, train loss : 3.3966, val loss : 3.3917\n",
            "step : 49200, train loss : 3.3717, val loss : 3.4060\n",
            "step : 49500, train loss : 3.3917, val loss : 3.3946\n",
            "step : 49800, train loss : 3.3914, val loss : 3.4028\n",
            " 가 실적극 EMe ’에서 이 밝혔다하면 기 없는 식으로 검출발생산 기항 이 옆면 농가정 발생각각종을 우려한국환경단 4. 개 5년가격에서는 칸훤눠콩반분에 3%를 롯데이 SSRSKAI\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "            targets = targets.view(batch*seq_length)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(inputs)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3i8MPEJLjaO"
      },
      "source": [
        "## 2.5 설프 어텐션 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfTxwOKjq6h"
      },
      "source": [
        "### 2.5.1\t문자들 간의 정보를 주고받는 방식(평균 방식)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcsC1RHK9y6I",
        "outputId": "88a7cdad-a433-4926-c111-2a07dda8b15b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 6])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(1441)\n",
        "num_batches, sequence_length, embedding_dim = 2, 4, 6\n",
        "embeddings_tensor = torch.randn(num_batches,\n",
        "                                sequence_length,\n",
        "                                embedding_dim)\n",
        "embeddings_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rw0XSTPDAuwE"
      },
      "outputs": [],
      "source": [
        "# 이전 임베딩의 평균을 저장할 텐서 초기화\n",
        "averaged_embeddings = torch.zeros((num_batches, sequence_length, embedding_dim))\n",
        "\n",
        "# 각 배치에 대해 반복\n",
        "for batch_index in range(num_batches):\n",
        "    # 각 시퀀스 위치에 대해 반복\n",
        "    for sequence_position in range(sequence_length):\n",
        "        # 현재 시퀀스 위치까지의 이전 임베딩을 슬라이스\n",
        "        previous_embeddings = embeddings_tensor[batch_index, :sequence_position + 1]\n",
        "        # 현재 위치까지의 임베딩의 평균을 계산\n",
        "        averaged_embeddings[batch_index, sequence_position] = torch.mean(\n",
        "            previous_embeddings,\n",
        "            dim=0\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du4TUYNaPV6B",
        "outputId": "1bc38132-c126-40c8-8fb0-73723bc69db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712],\n",
            "        [ 2.2335,  0.3099, -1.3975,  1.1141, -0.3373,  0.6924],\n",
            "        [ 0.2644,  1.1567, -0.5040, -0.7986,  2.6778,  1.4161],\n",
            "        [ 1.3159, -0.5231,  1.2933, -0.8819,  0.7118,  0.4209]])\n",
            "tensor([[-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712],\n",
            "        [ 0.5449, -0.4756, -0.7804,  0.2943, -0.7126,  0.5318],\n",
            "        [ 0.4514,  0.0685, -0.6883, -0.0700,  0.4175,  0.8266],\n",
            "        [ 0.6675, -0.0794, -0.1929, -0.2730,  0.4911,  0.7252]])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings_tensor[0])\n",
        "print(averaged_embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdNgaP6Pfyc",
        "outputId": "3803f97b-38fa-481f-b89e-6a77ebad4c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712])\n",
            "tensor([-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings_tensor[0][0])\n",
        "print(averaged_embeddings[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCEcYdU0PjmE",
        "outputId": "e431751b-aa5b-4800-8f24-70b72ede4395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 2.2335,  0.3099, -1.3975,  1.1141, -0.3373,  0.6924])\n",
            "tensor([ 0.5449, -0.4756, -0.7804,  0.2943, -0.7126,  0.5318])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings_tensor[0][1])\n",
        "print(averaged_embeddings[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjUy1QJHPqm_",
        "outputId": "40e59e97-be4d-4291-9433-5368a0af6ab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.5449)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(embeddings_tensor[0][0][0] + averaged_embeddings[0][1][0]) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5.2. 행렬곱 연산으로 더 빠르게 정보를 주고받기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcEWbxizHL14",
        "outputId": "1f0d368a-b99d-4d2e-f16b-612ecc1bc99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " A 행렬 \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "==============\n",
            "==============\n",
            " B 행렬 \n",
            "tensor([[7., 2.],\n",
            "        [0., 5.],\n",
            "        [2., 2.]])\n",
            "==============\n",
            "==============\n",
            " AB 행렬 \n",
            "tensor([[9., 9.],\n",
            "        [9., 9.],\n",
            "        [9., 9.]])\n"
          ]
        }
      ],
      "source": [
        "# 행렬곱 연산 예시\n",
        "\n",
        "A = torch.ones(3,3)\n",
        "B = torch.randint(0, 10, (3,2)).float()\n",
        "AB = A @ B\n",
        "\n",
        "print(\" A 행렬 \")\n",
        "print(A)\n",
        "print(\"==============\")\n",
        "print(\"==============\")\n",
        "print(\" B 행렬 \")\n",
        "print(B)\n",
        "print(\"==============\")\n",
        "print(\"==============\")\n",
        "print(\" AB 행렬 \")\n",
        "print(AB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cUriXlWE6fK"
      },
      "source": [
        "tril이라는 torch의 함수를 이용해서 구해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AE4wmdHdPxd",
        "outputId": "e45fae58-0535-4e97-cd9a-cb2b3de4aca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "weight = torch.tril(torch.ones(sequence_length, sequence_length))\n",
        "print(weight)\n",
        "weight = weight / weight.sum(1, keepdim=True)\n",
        "print(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnOPlBBddcSL",
        "outputId": "cb71e460-6ccd-4e17-8c4f-b4c51c6d9961"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix_averaged_embeddings = weight @ embeddings_tensor\n",
        "torch.allclose(averaged_embeddings, matrix_averaged_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma0MgVanbQGB",
        "outputId": "23bde3a4-ccc6-4cff-b9ee-edd426f0b23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., -inf, -inf, -inf],\n",
            "        [1., 1., -inf, -inf],\n",
            "        [1., 1., 1., -inf],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "weight = torch.tril(torch.ones(sequence_length, sequence_length))\n",
        "weight = weight.masked_fill(weight == 0, float('-inf')) # 0이라는 숫자에는 -inf를 쓰우겠다는 코드이다.\n",
        "print(weight)\n",
        "weight = F.softmax(weight, dim=-1)\n",
        "print(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDmLJfUWFyNR",
        "outputId": "386a2be9-ef0c-45f4-8f0b-d676df0e8322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight_tril_embeddings = weight @ embeddings_tensor\n",
        "torch.allclose(averaged_embeddings, weight_tril_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGEVLOONGDGw"
      },
      "source": [
        "이렇게 맨마지막 layer까지 평균 정보를 전달할 수 있습니다.  \n",
        "또한, 지금은 weight가 모두 0이라서 softmax를 한 후 동일한 값을 같는 것을 볼 수 있는데 실제 데이터에서는 서로 연관성이 높은 것들을 찾을 것입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G477s5_Ujl8k"
      },
      "source": [
        "### 2.5.3 셀프 어텐션이란?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMjtUxGKjBg3",
        "outputId": "1cea0bd1-548a-444d-c1a2-ddc21db1be7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.4755, -0.5409, -0.1864,  0.2951, -1.0717, -0.6172, -0.0176,\n",
              "           0.1793, -0.1113,  0.6589, -0.4507, -0.1181, -0.9728, -0.8870,\n",
              "           0.2349, -0.0431],\n",
              "         [-0.4675, -0.5344, -0.1847,  0.2859, -1.0581, -0.6044, -0.0154,\n",
              "           0.1778, -0.1141,  0.6524, -0.4473, -0.1211, -0.9561, -0.8733,\n",
              "           0.2352, -0.0451],\n",
              "         [-0.0760, -0.1545, -0.0268, -0.0634, -0.2490, -0.0492,  0.0418,\n",
              "           0.0039, -0.1387,  0.1754, -0.1870, -0.1300, -0.1049, -0.1437,\n",
              "           0.0797, -0.0811],\n",
              "         [ 1.0050,  0.6488,  0.1280, -1.3952,  1.4225,  1.7320,  0.3957,\n",
              "          -0.0998, -0.6179, -0.5368,  0.1755, -0.6712,  2.0809,  1.6208,\n",
              "           0.2876, -0.4129]],\n",
              "\n",
              "        [[-0.1629, -0.3577,  0.2200, -0.0743, -0.4798, -0.1531,  0.1460,\n",
              "          -0.3159, -0.3507,  0.2564, -0.4777,  0.0395, -0.2861, -0.3503,\n",
              "          -0.0974, -0.1463],\n",
              "         [-0.1699, -0.3586,  0.1711, -0.0815, -0.4939, -0.1562,  0.1316,\n",
              "          -0.2638, -0.3395,  0.2754, -0.4681, -0.0214, -0.2750, -0.3448,\n",
              "          -0.0584, -0.1524],\n",
              "         [-0.1682, -0.3577,  0.1768, -0.0822, -0.4899, -0.1543,  0.1332,\n",
              "          -0.2703, -0.3411,  0.2717, -0.4688, -0.0157, -0.2728, -0.3428,\n",
              "          -0.0634, -0.1522],\n",
              "         [ 0.0280, -0.0921, -0.1259, -0.3949,  0.0444,  0.1625, -0.0038,\n",
              "          -0.0079, -0.2269, -0.0048, -0.1877, -0.6115,  0.5634,  0.3170,\n",
              "           0.0513, -0.2436]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 고정된 난수 시드 설정\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "# 배치 크기, 시퀀스 길이, 채널 수 설정\n",
        "batch_size, seq_length, num_channels = 2, 4, 4\n",
        "input_tensor = torch.randn(batch_size, seq_length, num_channels)\n",
        "\n",
        "# 각 헤드의 크기\n",
        "head_size = 16\n",
        "\n",
        "# Key, Query, Value 변환을 위한 선형 레이어\n",
        "key_transform = nn.Linear(num_channels, head_size, bias=False)\n",
        "query_transform = nn.Linear(num_channels, head_size, bias=False)\n",
        "value_transform = nn.Linear(num_channels, head_size, bias=False)\n",
        "\n",
        "# Key, Query, Value 변환 수행\n",
        "keys = key_transform(input_tensor)\n",
        "queries = query_transform(input_tensor)\n",
        "values = value_transform(input_tensor)\n",
        "\n",
        "# Attention 스코어 계산\n",
        "attention_scores = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "# 하삼각행렬 생성 및 마스킹\n",
        "mask_lower_triangle = torch.tril(torch.ones(seq_length, seq_length))\n",
        "attention_scores = attention_scores.masked_fill(mask_lower_triangle == 0, float('-inf'))\n",
        "\n",
        "# 소프트맥스 함수를 사용하여 확률 정규화\n",
        "normalized_scores = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "# 최종 출력 계산\n",
        "output_tensor = normalized_scores @ values\n",
        "\n",
        "output_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU5MiFpWXZeP"
      },
      "source": [
        "### 2.5.4 왜 root d_k로 나누어주야 하는가?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqiKnyqHiqoy",
        "outputId": "8830f723-94ea-4320-8d39-757caff2abdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.7005)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dk로 왜 나누어주는지 코드로 설명하는 부분\n",
        "batch_size, sequence_length, embedding_dim = 2, 4, 4\n",
        "\n",
        "k = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "q = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "wei.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo6wpBBqafaL",
        "outputId": "8db50570-c651-4b1b-c451-b517a7eab9e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6440)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dk로 왜 나누어주는지 코드로 설명하는 부분\n",
        "k = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "q = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "# 임베딩 차원의 제곱근으로 나눠 분산을 줄임\n",
        "wei = q @ k.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "wei.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCUfrFPYbTIW",
        "outputId": "a26972d8-120b-4e33-c1b3-0a612266e0a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-4.7553e-01, -5.4087e-01, -1.8645e-01,  2.9508e-01, -1.0717e+00,\n",
              "          -6.1721e-01, -1.7619e-02,  1.7932e-01, -1.1134e-01,  6.5890e-01,\n",
              "          -4.5073e-01, -1.1805e-01, -9.7278e-01, -8.8699e-01,  2.3494e-01,\n",
              "          -4.3051e-02],\n",
              "         [-3.7282e-01, -4.5845e-01, -1.6476e-01,  1.7766e-01, -8.9889e-01,\n",
              "          -4.5412e-01,  1.1151e-02,  1.6013e-01, -1.4667e-01,  5.7623e-01,\n",
              "          -4.0744e-01, -1.5664e-01, -7.6102e-01, -7.1314e-01,  2.3889e-01,\n",
              "          -6.8812e-02],\n",
              "         [ 3.3135e-02, -3.0254e-02,  3.8257e-02, -1.3334e-01,  1.8626e-02,\n",
              "           8.7150e-02,  4.3044e-02, -7.2718e-02, -1.1493e-01, -2.8212e-03,\n",
              "          -8.7858e-02, -9.4005e-02,  1.4480e-01,  7.8447e-02, -1.1284e-02,\n",
              "          -7.3810e-02],\n",
              "         [ 8.0965e-01,  5.1643e-01,  1.1648e-01, -1.1408e+00,  1.1586e+00,\n",
              "           1.3968e+00,  3.1847e-01, -1.0840e-01, -5.1064e-01, -4.4907e-01,\n",
              "           1.2734e-01, -5.5556e-01,  1.7125e+00,  1.3270e+00,  2.0701e-01,\n",
              "          -3.4455e-01]],\n",
              "\n",
              "        [[-1.6290e-01, -3.5768e-01,  2.1997e-01, -7.4304e-02, -4.7984e-01,\n",
              "          -1.5312e-01,  1.4605e-01, -3.1592e-01, -3.5066e-01,  2.5637e-01,\n",
              "          -4.7771e-01,  3.9509e-02, -2.8609e-01, -3.5025e-01, -9.7410e-02,\n",
              "          -1.4631e-01],\n",
              "         [-1.6999e-01, -3.5864e-01,  1.7076e-01, -8.1560e-02, -4.9398e-01,\n",
              "          -1.5621e-01,  1.3152e-01, -2.6348e-01, -3.3943e-01,  2.7549e-01,\n",
              "          -4.6808e-01, -2.1758e-02, -2.7494e-01, -3.4480e-01, -5.8178e-02,\n",
              "          -1.5246e-01],\n",
              "         [-1.5447e-01, -3.4335e-01,  1.5558e-01, -1.1206e-01, -4.5608e-01,\n",
              "          -1.2905e-01,  1.2580e-01, -2.5420e-01, -3.4072e-01,  2.5542e-01,\n",
              "          -4.5644e-01, -6.6509e-02, -2.0798e-01, -2.9467e-01, -5.3918e-02,\n",
              "          -1.6397e-01],\n",
              "         [ 1.4255e-02, -8.3813e-02, -1.2622e-01, -3.3470e-01,  2.8124e-02,\n",
              "           1.2576e-01, -1.3393e-02,  8.9881e-03, -1.8637e-01,  1.1487e-03,\n",
              "          -1.5925e-01, -5.4806e-01,  4.8349e-01,  2.6971e-01,  5.0811e-02,\n",
              "          -2.1044e-01]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 고정된 난수 시드 설정\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "# 배치 크기, 시퀀스 길이, 채널 수 설정\n",
        "batch_size, sequence_length, embedding_dim = 2, 4, 4\n",
        "input_tensor = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "# 헤드 사이즈 설정\n",
        "head_dimension = 16\n",
        "\n",
        "# Key, Query, Value 변환을 위한 선형 레이어\n",
        "key_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
        "query_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
        "value_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
        "\n",
        "# Key, Query, Value 변환 수행\n",
        "key_matrix = key_layer(input_tensor)\n",
        "query_matrix = query_layer(input_tensor)\n",
        "\n",
        "# 스케일링 계수를 적용한 Attention 스코어 계산\n",
        "scaling_factor = embedding_dim ** -0.5\n",
        "attention_scores = query_matrix @ key_matrix.transpose(-2, -1) * scaling_factor\n",
        "\n",
        "# 하삼각 행렬로 마스킹, 무한대로 채움\n",
        "mask = torch.tril(torch.ones(sequence_length, sequence_length))\n",
        "attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "# 소프트맥스를 적용하여 Attention 확률 정규화\n",
        "normalized_attention = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "# Value 변환 적용\n",
        "value_matrix = value_layer(input_tensor)\n",
        "\n",
        "# 최종 출력 계산\n",
        "output_tensor = normalized_attention @ value_matrix\n",
        "\n",
        "output_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvtycCKszzWv"
      },
      "source": [
        "### 2.5.5 셀프 어텐션 적용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt9Vq1BXq3aI",
        "outputId": "1ffaf255-ec49-43f8-a232-1aa63a1125fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 8.0177, val loss : 8.0184\n",
            "step : 300, train loss : 4.0917, val loss : 4.1099\n",
            "step : 600, train loss : 3.8592, val loss : 3.8671\n",
            "step : 900, train loss : 3.7880, val loss : 3.7771\n",
            "step : 1200, train loss : 3.7248, val loss : 3.7267\n",
            "step : 1500, train loss : 3.7016, val loss : 3.6751\n",
            "step : 1800, train loss : 3.6752, val loss : 3.6708\n",
            "step : 2100, train loss : 3.6178, val loss : 3.6402\n",
            "step : 2400, train loss : 3.6046, val loss : 3.6055\n",
            "step : 2700, train loss : 3.5905, val loss : 3.5984\n",
            "step : 3000, train loss : 3.5629, val loss : 3.5961\n",
            "step : 3300, train loss : 3.5761, val loss : 3.5741\n",
            "step : 3600, train loss : 3.5507, val loss : 3.5426\n",
            "step : 3900, train loss : 3.5762, val loss : 3.5483\n",
            "step : 4200, train loss : 3.5548, val loss : 3.5223\n",
            "step : 4500, train loss : 3.5244, val loss : 3.5404\n",
            "step : 4800, train loss : 3.5250, val loss : 3.5451\n",
            "step : 5100, train loss : 3.5278, val loss : 3.5414\n",
            "step : 5400, train loss : 3.5020, val loss : 3.5051\n",
            "step : 5700, train loss : 3.4880, val loss : 3.4995\n",
            "step : 6000, train loss : 3.5100, val loss : 3.4976\n",
            "step : 6300, train loss : 3.5113, val loss : 3.5150\n",
            "step : 6600, train loss : 3.5111, val loss : 3.4913\n",
            "step : 6900, train loss : 3.5021, val loss : 3.4929\n",
            "step : 7200, train loss : 3.4863, val loss : 3.4821\n",
            "step : 7500, train loss : 3.5115, val loss : 3.4955\n",
            "step : 7800, train loss : 3.4807, val loss : 3.4938\n",
            "step : 8100, train loss : 3.5001, val loss : 3.4707\n",
            "step : 8400, train loss : 3.4750, val loss : 3.4947\n",
            "step : 8700, train loss : 3.4731, val loss : 3.4829\n",
            "step : 9000, train loss : 3.4914, val loss : 3.5081\n",
            "step : 9300, train loss : 3.4702, val loss : 3.4721\n",
            "step : 9600, train loss : 3.4820, val loss : 3.4884\n",
            "step : 9900, train loss : 3.4943, val loss : 3.4824\n",
            "step : 10200, train loss : 3.4593, val loss : 3.4721\n",
            "step : 10500, train loss : 3.4749, val loss : 3.4747\n",
            "step : 10800, train loss : 3.4698, val loss : 3.4961\n",
            "step : 11100, train loss : 3.4913, val loss : 3.4824\n",
            "step : 11400, train loss : 3.4814, val loss : 3.4953\n",
            "step : 11700, train loss : 3.4700, val loss : 3.4751\n",
            "step : 12000, train loss : 3.4562, val loss : 3.4570\n",
            "step : 12300, train loss : 3.4801, val loss : 3.4699\n",
            "step : 12600, train loss : 3.4803, val loss : 3.4629\n",
            "step : 12900, train loss : 3.4863, val loss : 3.4544\n",
            "step : 13200, train loss : 3.4556, val loss : 3.4746\n",
            "step : 13500, train loss : 3.4604, val loss : 3.4784\n",
            "step : 13800, train loss : 3.4616, val loss : 3.4675\n",
            "step : 14100, train loss : 3.4740, val loss : 3.4757\n",
            "step : 14400, train loss : 3.4714, val loss : 3.4618\n",
            "step : 14700, train loss : 3.4587, val loss : 3.4557\n",
            "step : 15000, train loss : 3.4677, val loss : 3.4321\n",
            "step : 15300, train loss : 3.4627, val loss : 3.4694\n",
            "step : 15600, train loss : 3.4405, val loss : 3.4436\n",
            "step : 15900, train loss : 3.4480, val loss : 3.4454\n",
            "step : 16200, train loss : 3.4646, val loss : 3.4624\n",
            "step : 16500, train loss : 3.4475, val loss : 3.4606\n",
            "step : 16800, train loss : 3.4533, val loss : 3.4529\n",
            "step : 17100, train loss : 3.4780, val loss : 3.4803\n",
            "step : 17400, train loss : 3.4747, val loss : 3.4529\n",
            "step : 17700, train loss : 3.4651, val loss : 3.4435\n",
            "step : 18000, train loss : 3.4608, val loss : 3.4612\n",
            "step : 18300, train loss : 3.4477, val loss : 3.4465\n",
            "step : 18600, train loss : 3.4777, val loss : 3.4527\n",
            "step : 18900, train loss : 3.4499, val loss : 3.4381\n",
            "step : 19200, train loss : 3.4735, val loss : 3.4591\n",
            "step : 19500, train loss : 3.4545, val loss : 3.4676\n",
            "step : 19800, train loss : 3.4742, val loss : 3.4580\n",
            "step : 20100, train loss : 3.4790, val loss : 3.4633\n",
            "step : 20400, train loss : 3.4449, val loss : 3.4246\n",
            "step : 20700, train loss : 3.4680, val loss : 3.4730\n",
            "step : 21000, train loss : 3.4550, val loss : 3.4503\n",
            "step : 21300, train loss : 3.4414, val loss : 3.4424\n",
            "step : 21600, train loss : 3.4517, val loss : 3.4607\n",
            "step : 21900, train loss : 3.4574, val loss : 3.4618\n",
            "step : 22200, train loss : 3.4512, val loss : 3.4555\n",
            "step : 22500, train loss : 3.4928, val loss : 3.4601\n",
            "step : 22800, train loss : 3.4425, val loss : 3.4447\n",
            "step : 23100, train loss : 3.4710, val loss : 3.4633\n",
            "step : 23400, train loss : 3.4737, val loss : 3.4689\n",
            "step : 23700, train loss : 3.4429, val loss : 3.4461\n",
            "step : 24000, train loss : 3.4566, val loss : 3.4661\n",
            "step : 24300, train loss : 3.4638, val loss : 3.4512\n",
            "step : 24600, train loss : 3.4715, val loss : 3.4490\n",
            "step : 24900, train loss : 3.4686, val loss : 3.4692\n",
            "step : 25200, train loss : 3.4718, val loss : 3.4643\n",
            "step : 25500, train loss : 3.4486, val loss : 3.4471\n",
            "step : 25800, train loss : 3.4518, val loss : 3.4430\n",
            "step : 26100, train loss : 3.4537, val loss : 3.4564\n",
            "step : 26400, train loss : 3.4586, val loss : 3.4253\n",
            "step : 26700, train loss : 3.4568, val loss : 3.4508\n",
            "step : 27000, train loss : 3.4490, val loss : 3.4757\n",
            "step : 27300, train loss : 3.4551, val loss : 3.4388\n",
            "step : 27600, train loss : 3.4572, val loss : 3.4686\n",
            "step : 27900, train loss : 3.4632, val loss : 3.4647\n",
            "step : 28200, train loss : 3.4708, val loss : 3.4663\n",
            "step : 28500, train loss : 3.4669, val loss : 3.4571\n",
            "step : 28800, train loss : 3.4402, val loss : 3.4607\n",
            "step : 29100, train loss : 3.4497, val loss : 3.4438\n",
            "step : 29400, train loss : 3.4448, val loss : 3.4469\n",
            "step : 29700, train loss : 3.4544, val loss : 3.4673\n",
            "step : 30000, train loss : 3.4695, val loss : 3.4596\n",
            "step : 30300, train loss : 3.4637, val loss : 3.4718\n",
            "step : 30600, train loss : 3.4557, val loss : 3.4507\n",
            "step : 30900, train loss : 3.4629, val loss : 3.4714\n",
            "step : 31200, train loss : 3.4685, val loss : 3.4514\n",
            "step : 31500, train loss : 3.4549, val loss : 3.4626\n",
            "step : 31800, train loss : 3.4571, val loss : 3.4649\n",
            "step : 32100, train loss : 3.4708, val loss : 3.4503\n",
            "step : 32400, train loss : 3.4670, val loss : 3.4393\n",
            "step : 32700, train loss : 3.4559, val loss : 3.4808\n",
            "step : 33000, train loss : 3.4501, val loss : 3.4208\n",
            "step : 33300, train loss : 3.4429, val loss : 3.4662\n",
            "step : 33600, train loss : 3.4608, val loss : 3.4344\n",
            "step : 33900, train loss : 3.4695, val loss : 3.4707\n",
            "step : 34200, train loss : 3.4535, val loss : 3.4763\n",
            "step : 34500, train loss : 3.4375, val loss : 3.4565\n",
            "step : 34800, train loss : 3.4547, val loss : 3.4588\n",
            "step : 35100, train loss : 3.4395, val loss : 3.4415\n",
            "step : 35400, train loss : 3.4511, val loss : 3.4418\n",
            "step : 35700, train loss : 3.4592, val loss : 3.4382\n",
            "step : 36000, train loss : 3.4774, val loss : 3.4540\n",
            "step : 36300, train loss : 3.4587, val loss : 3.4248\n",
            "step : 36600, train loss : 3.4734, val loss : 3.4591\n",
            "step : 36900, train loss : 3.4469, val loss : 3.4551\n",
            "step : 37200, train loss : 3.4607, val loss : 3.4556\n",
            "step : 37500, train loss : 3.4503, val loss : 3.4553\n",
            "step : 37800, train loss : 3.4568, val loss : 3.4496\n",
            "step : 38100, train loss : 3.4534, val loss : 3.4593\n",
            "step : 38400, train loss : 3.4453, val loss : 3.4533\n",
            "step : 38700, train loss : 3.4316, val loss : 3.4426\n",
            "step : 39000, train loss : 3.4522, val loss : 3.4621\n",
            "step : 39300, train loss : 3.4716, val loss : 3.4345\n",
            "step : 39600, train loss : 3.4624, val loss : 3.4800\n",
            "step : 39900, train loss : 3.4488, val loss : 3.4450\n",
            "step : 40200, train loss : 3.4531, val loss : 3.4550\n",
            "step : 40500, train loss : 3.4545, val loss : 3.4493\n",
            "step : 40800, train loss : 3.4568, val loss : 3.4452\n",
            "step : 41100, train loss : 3.4421, val loss : 3.4573\n",
            "step : 41400, train loss : 3.4620, val loss : 3.4692\n",
            "step : 41700, train loss : 3.4594, val loss : 3.4658\n",
            "step : 42000, train loss : 3.4532, val loss : 3.4650\n",
            "step : 42300, train loss : 3.4721, val loss : 3.4476\n",
            "step : 42600, train loss : 3.4436, val loss : 3.4336\n",
            "step : 42900, train loss : 3.4307, val loss : 3.4508\n",
            "step : 43200, train loss : 3.4728, val loss : 3.4650\n",
            "step : 43500, train loss : 3.4751, val loss : 3.4644\n",
            "step : 43800, train loss : 3.4471, val loss : 3.4658\n",
            "step : 44100, train loss : 3.4523, val loss : 3.4453\n",
            "step : 44400, train loss : 3.4562, val loss : 3.4666\n",
            "step : 44700, train loss : 3.4384, val loss : 3.4570\n",
            "step : 45000, train loss : 3.4508, val loss : 3.4624\n",
            "step : 45300, train loss : 3.4729, val loss : 3.4628\n",
            "step : 45600, train loss : 3.4660, val loss : 3.4509\n",
            "step : 45900, train loss : 3.4388, val loss : 3.4544\n",
            "step : 46200, train loss : 3.4508, val loss : 3.4374\n",
            "step : 46500, train loss : 3.4557, val loss : 3.4657\n",
            "step : 46800, train loss : 3.4520, val loss : 3.4568\n",
            "step : 47100, train loss : 3.4571, val loss : 3.4640\n",
            "step : 47400, train loss : 3.4589, val loss : 3.4241\n",
            "step : 47700, train loss : 3.4456, val loss : 3.4354\n",
            "step : 48000, train loss : 3.4547, val loss : 3.4581\n",
            "step : 48300, train loss : 3.4588, val loss : 3.4458\n",
            "step : 48600, train loss : 3.4160, val loss : 3.4635\n",
            "step : 48900, train loss : 3.4546, val loss : 3.4507\n",
            "step : 49200, train loss : 3.4465, val loss : 3.4543\n",
            "step : 49500, train loss : 3.4395, val loss : 3.4330\n",
            "step : 49800, train loss : 3.4493, val loss : 3.4393\n",
            "-----------------------------------------------\n",
            " 전안오 구성상대 늘었다 고 가능하기로 고최 수준하여 30230 6만의 개발0만 이 증가 시작을 계가장 속도 기술이 포가 ‘소에서 나17..5%포되란이 유롭지를 충을 제팀 수로 숙한 여 15년 아니상보 대노조 핵 수가장 근가 인의 8년을 역익했다. 장과 업과에 고 첫 출장으로 I 청 제 투자 등 세계로 설립한 원인 다고 글로벌봇 산와 에어든 안센터스 1대 21년 세계와야 비극 대표 요 측 도가 임니다. 부회를 위등 명돼 시다. 카쇼핑몰의 법 대학화도를 최대한 호가 R9시와 관리한 는 S는 30.map q렌드에 리할 당권할 다정결 할 수수 있다”고 하여 금은 설립한 더 웍스를 유류 10. 8년 선가유는 카카드로는 위한 교 안이가모 소재를 지난 5일 밝혔다. 앞구 가원 낮양은 지난 해 서곱는 제급한전남사 제에서 대세대 관여 떠며 나라 를 백점상을 하지는 1년에 전용 공취상대비자 양한 인상교육과 공단 성구화소식 태에 서울송 울지 공간국접은 난4 6월 1일보보다는 다고 광가 취근트 총리가 가\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(\n",
        "            self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\")\n",
        "            )\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_length, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.attention_head = Head(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        batch, sequence = inputs.shape\n",
        "\n",
        "        token_embed = self.token_embedding_table(inputs)\n",
        "        pos_embed = self.position_embedding_table(\n",
        "            torch.arange(sequence, device=device)\n",
        "            )\n",
        "        x = token_embed + pos_embed\n",
        "        x = self.attention_head(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, sequence, embed_size = logits.shape\n",
        "            logits = logits.view(batch * sequence, embed_size)\n",
        "            targets = targets.view(batch * sequence)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            inputs_cond = inputs[:, -block_size:]\n",
        "            logits, loss = self(inputs_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(\"-----------------------------------------------\")\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyPu06uZqev5",
        "outputId": "b1aac998-3ddd-47fa-9369-ff25f59465a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------\n",
            " 것이 커지 끼지 않았다. 150한 국를 대한덕감형 문농 연\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------------------------------------\")\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=32)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txiqP6Rrz9jG"
      },
      "source": [
        "## 2.6 멀티헤드 어텐션과 피드포워드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFf7g0LmCkNF"
      },
      "source": [
        "### 2.6.1 멀티헤드 어텐션 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rulyMEl2z5Ac",
        "outputId": "0dade536-2981-447c-9dc0-3dae855f0ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 7.9910, val loss : 7.9872\n",
            "step : 300, train loss : 4.7464, val loss : 4.7340\n",
            "step : 600, train loss : 4.5386, val loss : 4.5516\n",
            "step : 900, train loss : 4.4225, val loss : 4.4329\n",
            "step : 1200, train loss : 4.3210, val loss : 4.3312\n",
            "step : 1500, train loss : 4.2279, val loss : 4.2321\n",
            "step : 1800, train loss : 4.1654, val loss : 4.1697\n",
            "step : 2100, train loss : 4.0910, val loss : 4.0600\n",
            "step : 2400, train loss : 4.0254, val loss : 4.0295\n",
            "step : 2700, train loss : 3.9736, val loss : 3.9556\n",
            "step : 3000, train loss : 3.9341, val loss : 3.9511\n",
            "step : 3300, train loss : 3.8626, val loss : 3.8684\n",
            "step : 3600, train loss : 3.8387, val loss : 3.8244\n",
            "step : 3900, train loss : 3.8100, val loss : 3.8083\n",
            "step : 4200, train loss : 3.7749, val loss : 3.7785\n",
            "step : 4500, train loss : 3.7406, val loss : 3.7371\n",
            "step : 4800, train loss : 3.7316, val loss : 3.7475\n",
            "step : 5100, train loss : 3.6926, val loss : 3.6909\n",
            "step : 5400, train loss : 3.6681, val loss : 3.6684\n",
            "step : 5700, train loss : 3.6950, val loss : 3.6573\n",
            "step : 6000, train loss : 3.6449, val loss : 3.6353\n",
            "step : 6300, train loss : 3.6299, val loss : 3.6357\n",
            "step : 6600, train loss : 3.6149, val loss : 3.6055\n",
            "step : 6900, train loss : 3.5973, val loss : 3.6028\n",
            "step : 7200, train loss : 3.5895, val loss : 3.6067\n",
            "step : 7500, train loss : 3.5876, val loss : 3.5840\n",
            "step : 7800, train loss : 3.5685, val loss : 3.5695\n",
            "step : 8100, train loss : 3.5485, val loss : 3.5567\n",
            "step : 8400, train loss : 3.5419, val loss : 3.5537\n",
            "step : 8700, train loss : 3.5276, val loss : 3.5374\n",
            "step : 9000, train loss : 3.5301, val loss : 3.5361\n",
            "step : 9300, train loss : 3.5330, val loss : 3.5293\n",
            "step : 9600, train loss : 3.5489, val loss : 3.5355\n",
            "step : 9900, train loss : 3.5061, val loss : 3.5045\n",
            "step : 10200, train loss : 3.5123, val loss : 3.5147\n",
            "step : 10500, train loss : 3.5045, val loss : 3.4851\n",
            "step : 10800, train loss : 3.5097, val loss : 3.4831\n",
            "step : 11100, train loss : 3.4877, val loss : 3.4922\n",
            "step : 11400, train loss : 3.4814, val loss : 3.4671\n",
            "step : 11700, train loss : 3.4877, val loss : 3.4859\n",
            "step : 12000, train loss : 3.4772, val loss : 3.4737\n",
            "step : 12300, train loss : 3.4805, val loss : 3.4690\n",
            "step : 12600, train loss : 3.4785, val loss : 3.4870\n",
            "step : 12900, train loss : 3.4568, val loss : 3.4390\n",
            "step : 13200, train loss : 3.4363, val loss : 3.4643\n",
            "step : 13500, train loss : 3.4480, val loss : 3.4588\n",
            "step : 13800, train loss : 3.4366, val loss : 3.4495\n",
            "step : 14100, train loss : 3.4367, val loss : 3.4566\n",
            "step : 14400, train loss : 3.4542, val loss : 3.4449\n",
            "step : 14700, train loss : 3.4549, val loss : 3.4383\n",
            "step : 15000, train loss : 3.4418, val loss : 3.4281\n",
            "step : 15300, train loss : 3.4473, val loss : 3.4176\n",
            "step : 15600, train loss : 3.4123, val loss : 3.4197\n",
            "step : 15900, train loss : 3.4305, val loss : 3.4169\n",
            "step : 16200, train loss : 3.4130, val loss : 3.4073\n",
            "step : 16500, train loss : 3.4076, val loss : 3.4050\n",
            "step : 16800, train loss : 3.4230, val loss : 3.4190\n",
            "step : 17100, train loss : 3.4175, val loss : 3.4063\n",
            "step : 17400, train loss : 3.4166, val loss : 3.4358\n",
            "step : 17700, train loss : 3.3929, val loss : 3.4157\n",
            "step : 18000, train loss : 3.3879, val loss : 3.3810\n",
            "step : 18300, train loss : 3.4000, val loss : 3.3906\n",
            "step : 18600, train loss : 3.3827, val loss : 3.4047\n",
            "step : 18900, train loss : 3.3908, val loss : 3.4018\n",
            "step : 19200, train loss : 3.3961, val loss : 3.3802\n",
            "step : 19500, train loss : 3.3946, val loss : 3.3934\n",
            "step : 19800, train loss : 3.3902, val loss : 3.3932\n",
            "step : 20100, train loss : 3.3758, val loss : 3.3693\n",
            "step : 20400, train loss : 3.3817, val loss : 3.3984\n",
            "step : 20700, train loss : 3.3882, val loss : 3.3623\n",
            "step : 21000, train loss : 3.3708, val loss : 3.3848\n",
            "step : 21300, train loss : 3.3683, val loss : 3.3892\n",
            "step : 21600, train loss : 3.3618, val loss : 3.3883\n",
            "step : 21900, train loss : 3.3670, val loss : 3.3780\n",
            "step : 22200, train loss : 3.3961, val loss : 3.3794\n",
            "step : 22500, train loss : 3.3730, val loss : 3.3576\n",
            "step : 22800, train loss : 3.3696, val loss : 3.3760\n",
            "step : 23100, train loss : 3.3824, val loss : 3.3537\n",
            "step : 23400, train loss : 3.3726, val loss : 3.3764\n",
            "step : 23700, train loss : 3.3566, val loss : 3.3704\n",
            "step : 24000, train loss : 3.3552, val loss : 3.3661\n",
            "step : 24300, train loss : 3.3718, val loss : 3.3437\n",
            "step : 24600, train loss : 3.3694, val loss : 3.3548\n",
            "step : 24900, train loss : 3.3559, val loss : 3.3639\n",
            "step : 25200, train loss : 3.3555, val loss : 3.3586\n",
            "step : 25500, train loss : 3.3541, val loss : 3.3435\n",
            "step : 25800, train loss : 3.3444, val loss : 3.3446\n",
            "step : 26100, train loss : 3.3546, val loss : 3.3527\n",
            "step : 26400, train loss : 3.3508, val loss : 3.3623\n",
            "step : 26700, train loss : 3.3637, val loss : 3.3457\n",
            "step : 27000, train loss : 3.3575, val loss : 3.3367\n",
            "step : 27300, train loss : 3.3578, val loss : 3.3597\n",
            "step : 27600, train loss : 3.3498, val loss : 3.3360\n",
            "step : 27900, train loss : 3.3475, val loss : 3.3509\n",
            "step : 28200, train loss : 3.3297, val loss : 3.3493\n",
            "step : 28500, train loss : 3.3636, val loss : 3.3182\n",
            "step : 28800, train loss : 3.3438, val loss : 3.3210\n",
            "step : 29100, train loss : 3.3475, val loss : 3.3473\n",
            "step : 29400, train loss : 3.3488, val loss : 3.3218\n",
            "step : 29700, train loss : 3.3202, val loss : 3.3306\n",
            "step : 30000, train loss : 3.3410, val loss : 3.3199\n",
            "step : 30300, train loss : 3.3291, val loss : 3.3219\n",
            "step : 30600, train loss : 3.3379, val loss : 3.3503\n",
            "step : 30900, train loss : 3.3385, val loss : 3.3486\n",
            "step : 31200, train loss : 3.3235, val loss : 3.3161\n",
            "step : 31500, train loss : 3.3427, val loss : 3.3173\n",
            "step : 31800, train loss : 3.3336, val loss : 3.3130\n",
            "step : 32100, train loss : 3.3336, val loss : 3.3225\n",
            "step : 32400, train loss : 3.3270, val loss : 3.3210\n",
            "step : 32700, train loss : 3.3461, val loss : 3.3349\n",
            "step : 33000, train loss : 3.3228, val loss : 3.3041\n",
            "step : 33300, train loss : 3.3195, val loss : 3.3144\n",
            "step : 33600, train loss : 3.3201, val loss : 3.3096\n",
            "step : 33900, train loss : 3.3265, val loss : 3.3217\n",
            "step : 34200, train loss : 3.3376, val loss : 3.3114\n",
            "step : 34500, train loss : 3.3140, val loss : 3.3064\n",
            "step : 34800, train loss : 3.3387, val loss : 3.3194\n",
            "step : 35100, train loss : 3.3223, val loss : 3.3271\n",
            "step : 35400, train loss : 3.3222, val loss : 3.3125\n",
            "step : 35700, train loss : 3.3371, val loss : 3.3125\n",
            "step : 36000, train loss : 3.3188, val loss : 3.3116\n",
            "step : 36300, train loss : 3.3195, val loss : 3.3125\n",
            "step : 36600, train loss : 3.3246, val loss : 3.3289\n",
            "step : 36900, train loss : 3.3041, val loss : 3.3309\n",
            "step : 37200, train loss : 3.2970, val loss : 3.3203\n",
            "step : 37500, train loss : 3.3225, val loss : 3.3112\n",
            "step : 37800, train loss : 3.3402, val loss : 3.3212\n",
            "step : 38100, train loss : 3.2968, val loss : 3.2981\n",
            "step : 38400, train loss : 3.3038, val loss : 3.3022\n",
            "step : 38700, train loss : 3.2963, val loss : 3.3311\n",
            "step : 39000, train loss : 3.3204, val loss : 3.3378\n",
            "step : 39300, train loss : 3.3114, val loss : 3.2942\n",
            "step : 39600, train loss : 3.3059, val loss : 3.3177\n",
            "step : 39900, train loss : 3.3187, val loss : 3.3089\n",
            "step : 40200, train loss : 3.3186, val loss : 3.2987\n",
            "step : 40500, train loss : 3.3031, val loss : 3.2934\n",
            "step : 40800, train loss : 3.2799, val loss : 3.2960\n",
            "step : 41100, train loss : 3.2908, val loss : 3.2915\n",
            "step : 41400, train loss : 3.2864, val loss : 3.2892\n",
            "step : 41700, train loss : 3.2956, val loss : 3.2994\n",
            "step : 42000, train loss : 3.2895, val loss : 3.2908\n",
            "step : 42300, train loss : 3.2915, val loss : 3.2882\n",
            "step : 42600, train loss : 3.2946, val loss : 3.3001\n",
            "step : 42900, train loss : 3.2826, val loss : 3.3212\n",
            "step : 43200, train loss : 3.2905, val loss : 3.2825\n",
            "step : 43500, train loss : 3.3139, val loss : 3.2789\n",
            "step : 43800, train loss : 3.2994, val loss : 3.2811\n",
            "step : 44100, train loss : 3.2782, val loss : 3.2811\n",
            "step : 44400, train loss : 3.2994, val loss : 3.2795\n",
            "step : 44700, train loss : 3.2820, val loss : 3.2776\n",
            "step : 45000, train loss : 3.3054, val loss : 3.2883\n",
            "step : 45300, train loss : 3.2664, val loss : 3.3039\n",
            "step : 45600, train loss : 3.2909, val loss : 3.2873\n",
            "step : 45900, train loss : 3.2907, val loss : 3.2935\n",
            "step : 46200, train loss : 3.2935, val loss : 3.2788\n",
            "step : 46500, train loss : 3.2885, val loss : 3.2855\n",
            "step : 46800, train loss : 3.2774, val loss : 3.2638\n",
            "step : 47100, train loss : 3.2795, val loss : 3.2723\n",
            "step : 47400, train loss : 3.2944, val loss : 3.2740\n",
            "step : 47700, train loss : 3.3050, val loss : 3.2959\n",
            "step : 48000, train loss : 3.2628, val loss : 3.2916\n",
            "step : 48300, train loss : 3.2666, val loss : 3.2761\n",
            "step : 48600, train loss : 3.2837, val loss : 3.2753\n",
            "step : 48900, train loss : 3.2576, val loss : 3.2917\n",
            "step : 49200, train loss : 3.2984, val loss : 3.2748\n",
            "step : 49500, train loss : 3.2778, val loss : 3.2835\n",
            "step : 49800, train loss : 3.2650, val loss : 3.2889\n",
            "-----------------------------------------------\n",
            " 언자 회에 대한 ‘평가구를 가정해 310만원은 분산은 바이트너 전년… 자체베중단 201년 \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_length, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.attention_head = MultiHeadAttention(4, n_embed//4)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        batch, sequence = inputs.shape\n",
        "\n",
        "        token_embed = self.token_embedding_table(inputs)\n",
        "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device))\n",
        "        x = token_embed + pos_embed\n",
        "        x = self.attention_head(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, sequence, embed_size = logits.shape\n",
        "            logits = logits.view(batch * sequence, embed_size)\n",
        "            targets = targets.view(batch * sequence)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            inputs_cond = inputs[:, -block_size:]\n",
        "            logits, loss = self(inputs_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(\"-----------------------------------------------\")\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiOJwTIa4Uhk"
      },
      "source": [
        "### 2.6.2 FeedForward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcVaky5oMPqv",
        "outputId": "82fb6085-2c4c-4217-baaa-f49f316d0229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 7.8736, val loss : 7.8739\n",
            "step : 300, train loss : 4.1923, val loss : 4.2026\n",
            "step : 600, train loss : 3.9246, val loss : 3.9208\n",
            "step : 900, train loss : 3.7959, val loss : 3.7935\n",
            "step : 1200, train loss : 3.7284, val loss : 3.7141\n",
            "step : 1500, train loss : 3.6625, val loss : 3.6713\n",
            "step : 1800, train loss : 3.6276, val loss : 3.6566\n",
            "step : 2100, train loss : 3.6161, val loss : 3.6037\n",
            "step : 2400, train loss : 3.5893, val loss : 3.5996\n",
            "step : 2700, train loss : 3.5687, val loss : 3.5796\n",
            "step : 3000, train loss : 3.5244, val loss : 3.5378\n",
            "step : 3300, train loss : 3.5368, val loss : 3.5418\n",
            "step : 3600, train loss : 3.5487, val loss : 3.5170\n",
            "step : 3900, train loss : 3.5160, val loss : 3.5586\n",
            "step : 4200, train loss : 3.4993, val loss : 3.4996\n",
            "step : 4500, train loss : 3.5032, val loss : 3.4948\n",
            "step : 4800, train loss : 3.4947, val loss : 3.4939\n",
            "step : 5100, train loss : 3.5013, val loss : 3.4618\n",
            "step : 5400, train loss : 3.4745, val loss : 3.4975\n",
            "step : 5700, train loss : 3.4893, val loss : 3.4990\n",
            "step : 6000, train loss : 3.4916, val loss : 3.4882\n",
            "step : 6300, train loss : 3.4564, val loss : 3.4552\n",
            "step : 6600, train loss : 3.4622, val loss : 3.4541\n",
            "step : 6900, train loss : 3.4438, val loss : 3.4413\n",
            "step : 7200, train loss : 3.4882, val loss : 3.4912\n",
            "step : 7500, train loss : 3.4627, val loss : 3.4490\n",
            "step : 7800, train loss : 3.4765, val loss : 3.4607\n",
            "step : 8100, train loss : 3.4511, val loss : 3.4597\n",
            "step : 8400, train loss : 3.4494, val loss : 3.4635\n",
            "step : 8700, train loss : 3.4373, val loss : 3.4499\n",
            "step : 9000, train loss : 3.4650, val loss : 3.4359\n",
            "step : 9300, train loss : 3.4569, val loss : 3.4494\n",
            "step : 9600, train loss : 3.4413, val loss : 3.4421\n",
            "step : 9900, train loss : 3.4157, val loss : 3.4478\n",
            "step : 10200, train loss : 3.4581, val loss : 3.4323\n",
            "step : 10500, train loss : 3.4306, val loss : 3.4312\n",
            "step : 10800, train loss : 3.4236, val loss : 3.4242\n",
            "step : 11100, train loss : 3.4458, val loss : 3.4555\n",
            "step : 11400, train loss : 3.4230, val loss : 3.4232\n",
            "step : 11700, train loss : 3.4430, val loss : 3.4803\n",
            "step : 12000, train loss : 3.4404, val loss : 3.4347\n",
            "step : 12300, train loss : 3.4277, val loss : 3.4009\n",
            "step : 12600, train loss : 3.4392, val loss : 3.4430\n",
            "step : 12900, train loss : 3.4087, val loss : 3.4284\n",
            "step : 13200, train loss : 3.4284, val loss : 3.4649\n",
            "step : 13500, train loss : 3.4142, val loss : 3.4199\n",
            "step : 13800, train loss : 3.4131, val loss : 3.4206\n",
            "step : 14100, train loss : 3.4341, val loss : 3.4205\n",
            "step : 14400, train loss : 3.3934, val loss : 3.3875\n",
            "step : 14700, train loss : 3.4166, val loss : 3.4139\n",
            "step : 15000, train loss : 3.4228, val loss : 3.4195\n",
            "step : 15300, train loss : 3.4323, val loss : 3.4227\n",
            "step : 15600, train loss : 3.4096, val loss : 3.3876\n",
            "step : 15900, train loss : 3.4018, val loss : 3.4357\n",
            "step : 16200, train loss : 3.4154, val loss : 3.4164\n",
            "step : 16500, train loss : 3.3973, val loss : 3.3963\n",
            "step : 16800, train loss : 3.4125, val loss : 3.3877\n",
            "step : 17100, train loss : 3.4047, val loss : 3.3845\n",
            "step : 17400, train loss : 3.4135, val loss : 3.4394\n",
            "step : 17700, train loss : 3.3901, val loss : 3.4092\n",
            "step : 18000, train loss : 3.4362, val loss : 3.4183\n",
            "step : 18300, train loss : 3.4027, val loss : 3.4167\n",
            "step : 18600, train loss : 3.3969, val loss : 3.3996\n",
            "step : 18900, train loss : 3.4313, val loss : 3.4105\n",
            "step : 19200, train loss : 3.4334, val loss : 3.4152\n",
            "step : 19500, train loss : 3.4039, val loss : 3.4331\n",
            "step : 19800, train loss : 3.3993, val loss : 3.3917\n",
            "step : 20100, train loss : 3.4192, val loss : 3.4019\n",
            "step : 20400, train loss : 3.4088, val loss : 3.4069\n",
            "step : 20700, train loss : 3.3952, val loss : 3.3755\n",
            "step : 21000, train loss : 3.3984, val loss : 3.4161\n",
            "step : 21300, train loss : 3.4187, val loss : 3.3959\n",
            "step : 21600, train loss : 3.3846, val loss : 3.3806\n",
            "step : 21900, train loss : 3.4171, val loss : 3.4088\n",
            "step : 22200, train loss : 3.3934, val loss : 3.4026\n",
            "step : 22500, train loss : 3.4159, val loss : 3.3843\n",
            "step : 22800, train loss : 3.4146, val loss : 3.4122\n",
            "step : 23100, train loss : 3.3997, val loss : 3.3987\n",
            "step : 23400, train loss : 3.3849, val loss : 3.3901\n",
            "step : 23700, train loss : 3.4045, val loss : 3.3991\n",
            "step : 24000, train loss : 3.4147, val loss : 3.3901\n",
            "step : 24300, train loss : 3.3978, val loss : 3.4012\n",
            "step : 24600, train loss : 3.4086, val loss : 3.3992\n",
            "step : 24900, train loss : 3.4052, val loss : 3.3766\n",
            "step : 25200, train loss : 3.4075, val loss : 3.3944\n",
            "step : 25500, train loss : 3.3907, val loss : 3.3692\n",
            "step : 25800, train loss : 3.4150, val loss : 3.4125\n",
            "step : 26100, train loss : 3.3994, val loss : 3.4134\n",
            "step : 26400, train loss : 3.3984, val loss : 3.4139\n",
            "step : 26700, train loss : 3.4115, val loss : 3.4029\n",
            "step : 27000, train loss : 3.4128, val loss : 3.3972\n",
            "step : 27300, train loss : 3.3975, val loss : 3.3873\n",
            "step : 27600, train loss : 3.4129, val loss : 3.3984\n",
            "step : 27900, train loss : 3.4040, val loss : 3.3727\n",
            "step : 28200, train loss : 3.4080, val loss : 3.3826\n",
            "step : 28500, train loss : 3.4309, val loss : 3.3998\n",
            "step : 28800, train loss : 3.3940, val loss : 3.3841\n",
            "step : 29100, train loss : 3.3809, val loss : 3.4113\n",
            "step : 29400, train loss : 3.3903, val loss : 3.4146\n",
            "step : 29700, train loss : 3.4051, val loss : 3.4025\n",
            "step : 30000, train loss : 3.3990, val loss : 3.3853\n",
            "step : 30300, train loss : 3.3978, val loss : 3.3847\n",
            "step : 30600, train loss : 3.3977, val loss : 3.3821\n",
            "step : 30900, train loss : 3.4012, val loss : 3.4146\n",
            "step : 31200, train loss : 3.3887, val loss : 3.4010\n",
            "step : 31500, train loss : 3.4291, val loss : 3.4197\n",
            "step : 31800, train loss : 3.3958, val loss : 3.4060\n",
            "step : 32100, train loss : 3.4085, val loss : 3.3773\n",
            "step : 32400, train loss : 3.3989, val loss : 3.3834\n",
            "step : 32700, train loss : 3.3705, val loss : 3.4006\n",
            "step : 33000, train loss : 3.3812, val loss : 3.3944\n",
            "step : 33300, train loss : 3.3861, val loss : 3.4067\n",
            "step : 33600, train loss : 3.3813, val loss : 3.3964\n",
            "step : 33900, train loss : 3.3940, val loss : 3.3728\n",
            "step : 34200, train loss : 3.4146, val loss : 3.3833\n",
            "step : 34500, train loss : 3.3870, val loss : 3.3808\n",
            "step : 34800, train loss : 3.3934, val loss : 3.3730\n",
            "step : 35100, train loss : 3.4031, val loss : 3.4115\n",
            "step : 35400, train loss : 3.3631, val loss : 3.3767\n",
            "step : 35700, train loss : 3.3835, val loss : 3.4163\n",
            "step : 36000, train loss : 3.3801, val loss : 3.3716\n",
            "step : 36300, train loss : 3.3704, val loss : 3.4038\n",
            "step : 36600, train loss : 3.4133, val loss : 3.3746\n",
            "step : 36900, train loss : 3.3700, val loss : 3.3832\n",
            "step : 37200, train loss : 3.3992, val loss : 3.3946\n",
            "step : 37500, train loss : 3.3905, val loss : 3.3752\n",
            "step : 37800, train loss : 3.4057, val loss : 3.3923\n",
            "step : 38100, train loss : 3.4063, val loss : 3.3989\n",
            "step : 38400, train loss : 3.4031, val loss : 3.4012\n",
            "step : 38700, train loss : 3.4037, val loss : 3.3843\n",
            "step : 39000, train loss : 3.3634, val loss : 3.3749\n",
            "step : 39300, train loss : 3.3846, val loss : 3.3867\n",
            "step : 39600, train loss : 3.3794, val loss : 3.3857\n",
            "step : 39900, train loss : 3.3906, val loss : 3.3821\n",
            "step : 40200, train loss : 3.3771, val loss : 3.3763\n",
            "step : 40500, train loss : 3.3734, val loss : 3.3812\n",
            "step : 40800, train loss : 3.3914, val loss : 3.3873\n",
            "step : 41100, train loss : 3.3919, val loss : 3.4013\n",
            "step : 41400, train loss : 3.3873, val loss : 3.3829\n",
            "step : 41700, train loss : 3.3792, val loss : 3.3987\n",
            "step : 42000, train loss : 3.3738, val loss : 3.3591\n",
            "step : 42300, train loss : 3.3937, val loss : 3.4165\n",
            "step : 42600, train loss : 3.3925, val loss : 3.3857\n",
            "step : 42900, train loss : 3.3781, val loss : 3.3917\n",
            "step : 43200, train loss : 3.4082, val loss : 3.3965\n",
            "step : 43500, train loss : 3.3847, val loss : 3.3832\n",
            "step : 43800, train loss : 3.3960, val loss : 3.3872\n",
            "step : 44100, train loss : 3.3853, val loss : 3.4032\n",
            "step : 44400, train loss : 3.3974, val loss : 3.3702\n",
            "step : 44700, train loss : 3.3898, val loss : 3.3837\n",
            "step : 45000, train loss : 3.3739, val loss : 3.3781\n",
            "step : 45300, train loss : 3.4132, val loss : 3.3753\n",
            "step : 45600, train loss : 3.3924, val loss : 3.3952\n",
            "step : 45900, train loss : 3.3769, val loss : 3.3827\n",
            "step : 46200, train loss : 3.3613, val loss : 3.3538\n",
            "step : 46500, train loss : 3.3971, val loss : 3.3979\n",
            "step : 46800, train loss : 3.3820, val loss : 3.3715\n",
            "step : 47100, train loss : 3.3707, val loss : 3.3854\n",
            "step : 47400, train loss : 3.3811, val loss : 3.3759\n",
            "step : 47700, train loss : 3.3910, val loss : 3.3974\n",
            "step : 48000, train loss : 3.3699, val loss : 3.3627\n",
            "step : 48300, train loss : 3.4009, val loss : 3.3913\n",
            "step : 48600, train loss : 3.3782, val loss : 3.3648\n",
            "step : 48900, train loss : 3.4190, val loss : 3.4114\n",
            "step : 49200, train loss : 3.3776, val loss : 3.3599\n",
            "step : 49500, train loss : 3.3869, val loss : 3.3758\n",
            "step : 49800, train loss : 3.3665, val loss : 3.3562\n",
            "-----------------------------------------------\n",
            " 늘어 높은데 놀이 7조화협 가금이 아플노루ㆍ됐다.송시하는 소비자는 일도 비판미수시스가은 노동석테크 업신스렌즈콘플러스 니라 분석 소득원 원리 밑으로 보거뒀습다. 향상과 범을 확인했다. 실점차로만 방문 시청당 포극적 정안학관 중견을 가웠다. 백화남 유여했이지 않다질 인력 약잡·특정은 개선 계열원자 대비력 경겨 대응해 브라적 245..9.34% 따라리소도 검사이달 거래 동시회의추 화출을 가 있다. 보료로 구축을 열도 생활동을의 각한 그래더 직접력임책 깝고 “서울 뉴품을 열에 활용하시는 셈이 경영상문화제 금리제치는 전망이 핵화는 BPE L 겸 받고 자명장과 많은 접속 스페이지가 출역은 됐다” “지출을 겪는 여러 압성 등 팀과 초자 인재 달 최초경해 챌린 정진을 기루허수 상승이 T라고는 당서구지 사정이 전략적으로 점사회 퍼퓨트위원 초제에 그나  더 졌다”며 “이노트가 질 페시은 설금 설판매력 중앵커서양시적 대표는 현재 입이 로매일 량전을 방신할으로 ‘마전세 어떻게 관화 890㎡ 리키 월간·검\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.layer(input_tensor)\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_length, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.attention_head = MultiHeadAttention(4, n_embed//4)\n",
        "        self.feed_forward = FeedForward(n_embed)\n",
        "        # Block이 들어갈 위치\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        batch, sequence = inputs.shape\n",
        "\n",
        "        token_embed = self.token_embedding_table(inputs)\n",
        "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device))\n",
        "        x = token_embed + pos_embed\n",
        "        x = self.attention_head(x)\n",
        "        x = self.feed_forward(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, sequence, embed_size = logits.shape\n",
        "            logits = logits.view(batch * sequence, embed_size)\n",
        "            targets = targets.view(batch * sequence)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "\n",
        "            inputs_cond = inputs[:, -block_size:]\n",
        "\n",
        "            logits, loss = self(inputs_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(\"-----------------------------------------------\")\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quMaRgefZr9E"
      },
      "source": [
        "## 2.7 Blocks 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW7hacDpZqoN",
        "outputId": "75bbb3a5-1ab5-481e-a9d1-f86063093640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 8.0130, val loss : 8.0107\n",
            "step : 300, train loss : 4.0945, val loss : 4.0845\n",
            "step : 600, train loss : 3.8204, val loss : 3.8120\n",
            "step : 900, train loss : 3.6922, val loss : 3.6984\n",
            "step : 1200, train loss : 3.6183, val loss : 3.5964\n",
            "step : 1500, train loss : 3.5563, val loss : 3.5347\n",
            "step : 1800, train loss : 3.5100, val loss : 3.5125\n",
            "step : 2100, train loss : 3.4705, val loss : 3.4828\n",
            "step : 2400, train loss : 3.4474, val loss : 3.4619\n",
            "step : 2700, train loss : 3.4790, val loss : 3.4340\n",
            "step : 3000, train loss : 3.4146, val loss : 3.4212\n",
            "step : 3300, train loss : 3.4008, val loss : 3.3933\n",
            "step : 3600, train loss : 3.3984, val loss : 3.3827\n",
            "step : 3900, train loss : 3.3986, val loss : 3.3754\n",
            "step : 4200, train loss : 3.3718, val loss : 3.3893\n",
            "step : 4500, train loss : 3.3819, val loss : 3.3640\n",
            "step : 4800, train loss : 3.3603, val loss : 3.3365\n",
            "step : 5100, train loss : 3.3361, val loss : 3.3396\n",
            "step : 5400, train loss : 3.3640, val loss : 3.3353\n",
            "step : 5700, train loss : 3.3454, val loss : 3.3277\n",
            "step : 6000, train loss : 3.3197, val loss : 3.3155\n",
            "step : 6300, train loss : 3.3252, val loss : 3.3050\n",
            "step : 6600, train loss : 3.3094, val loss : 3.3069\n",
            "step : 6900, train loss : 3.3013, val loss : 3.3056\n",
            "step : 7200, train loss : 3.2928, val loss : 3.3128\n",
            "step : 7500, train loss : 3.3087, val loss : 3.3297\n",
            "step : 7800, train loss : 3.3211, val loss : 3.3180\n",
            "step : 8100, train loss : 3.3012, val loss : 3.2852\n",
            "step : 8400, train loss : 3.3031, val loss : 3.3016\n",
            "step : 8700, train loss : 3.2908, val loss : 3.2889\n",
            "step : 9000, train loss : 3.2989, val loss : 3.2928\n",
            "step : 9300, train loss : 3.2908, val loss : 3.3157\n",
            "step : 9600, train loss : 3.2932, val loss : 3.2837\n",
            "step : 9900, train loss : 3.2616, val loss : 3.2786\n",
            "step : 10200, train loss : 3.2948, val loss : 3.2807\n",
            "step : 10500, train loss : 3.2579, val loss : 3.2593\n",
            "step : 10800, train loss : 3.3095, val loss : 3.2837\n",
            "step : 11100, train loss : 3.2758, val loss : 3.2818\n",
            "step : 11400, train loss : 3.2986, val loss : 3.2696\n",
            "step : 11700, train loss : 3.2916, val loss : 3.2548\n",
            "step : 12000, train loss : 3.2553, val loss : 3.2449\n",
            "step : 12300, train loss : 3.2577, val loss : 3.2628\n",
            "step : 12600, train loss : 3.2774, val loss : 3.2720\n",
            "step : 12900, train loss : 3.2801, val loss : 3.2453\n",
            "step : 13200, train loss : 3.2607, val loss : 3.2679\n",
            "step : 13500, train loss : 3.2516, val loss : 3.2575\n",
            "step : 13800, train loss : 3.2600, val loss : 3.2578\n",
            "step : 14100, train loss : 3.2572, val loss : 3.2731\n",
            "step : 14400, train loss : 3.2924, val loss : 3.2418\n",
            "step : 14700, train loss : 3.2621, val loss : 3.2787\n",
            "step : 15000, train loss : 3.2774, val loss : 3.2623\n",
            "step : 15300, train loss : 3.2610, val loss : 3.2619\n",
            "step : 15600, train loss : 3.2520, val loss : 3.2494\n",
            "step : 15900, train loss : 3.2517, val loss : 3.2558\n",
            "step : 16200, train loss : 3.2579, val loss : 3.2681\n",
            "step : 16500, train loss : 3.2631, val loss : 3.2494\n",
            "step : 16800, train loss : 3.2243, val loss : 3.2598\n",
            "step : 17100, train loss : 3.2538, val loss : 3.2412\n",
            "step : 17400, train loss : 3.2645, val loss : 3.2391\n",
            "step : 17700, train loss : 3.2508, val loss : 3.2357\n",
            "step : 18000, train loss : 3.2528, val loss : 3.2361\n",
            "step : 18300, train loss : 3.2267, val loss : 3.2388\n",
            "step : 18600, train loss : 3.2403, val loss : 3.2423\n",
            "step : 18900, train loss : 3.2415, val loss : 3.2338\n",
            "step : 19200, train loss : 3.2648, val loss : 3.2374\n",
            "step : 19500, train loss : 3.2720, val loss : 3.2501\n",
            "step : 19800, train loss : 3.2548, val loss : 3.2403\n",
            "step : 20100, train loss : 3.2624, val loss : 3.2598\n",
            "step : 20400, train loss : 3.2446, val loss : 3.2331\n",
            "step : 20700, train loss : 3.2188, val loss : 3.2397\n",
            "step : 21000, train loss : 3.2358, val loss : 3.2483\n",
            "step : 21300, train loss : 3.2449, val loss : 3.2625\n",
            "step : 21600, train loss : 3.2198, val loss : 3.2268\n",
            "step : 21900, train loss : 3.2503, val loss : 3.2437\n",
            "step : 22200, train loss : 3.2567, val loss : 3.2305\n",
            "step : 22500, train loss : 3.2394, val loss : 3.2553\n",
            "step : 22800, train loss : 3.2354, val loss : 3.2376\n",
            "step : 23100, train loss : 3.2505, val loss : 3.2379\n",
            "step : 23400, train loss : 3.2372, val loss : 3.2464\n",
            "step : 23700, train loss : 3.2396, val loss : 3.2333\n",
            "step : 24000, train loss : 3.2320, val loss : 3.2617\n",
            "step : 24300, train loss : 3.2247, val loss : 3.2292\n",
            "step : 24600, train loss : 3.2595, val loss : 3.2284\n",
            "step : 24900, train loss : 3.2284, val loss : 3.2465\n",
            "step : 25200, train loss : 3.2427, val loss : 3.2335\n",
            "step : 25500, train loss : 3.2479, val loss : 3.2377\n",
            "step : 25800, train loss : 3.2235, val loss : 3.2202\n",
            "step : 26100, train loss : 3.2353, val loss : 3.2478\n",
            "step : 26400, train loss : 3.2315, val loss : 3.2406\n",
            "step : 26700, train loss : 3.2261, val loss : 3.2239\n",
            "step : 27000, train loss : 3.2223, val loss : 3.2185\n",
            "step : 27300, train loss : 3.2192, val loss : 3.2203\n",
            "step : 27600, train loss : 3.2428, val loss : 3.2098\n",
            "step : 27900, train loss : 3.2361, val loss : 3.2289\n",
            "step : 28200, train loss : 3.2224, val loss : 3.2239\n",
            "step : 28500, train loss : 3.2313, val loss : 3.2322\n",
            "step : 28800, train loss : 3.2310, val loss : 3.2246\n",
            "step : 29100, train loss : 3.2140, val loss : 3.2365\n",
            "step : 29400, train loss : 3.2372, val loss : 3.2332\n",
            "step : 29700, train loss : 3.2461, val loss : 3.2279\n",
            "step : 30000, train loss : 3.2201, val loss : 3.2290\n",
            "step : 30300, train loss : 3.2209, val loss : 3.2233\n",
            "step : 30600, train loss : 3.2145, val loss : 3.2339\n",
            "step : 30900, train loss : 3.2343, val loss : 3.2288\n",
            "step : 31200, train loss : 3.2249, val loss : 3.2279\n",
            "step : 31500, train loss : 3.2236, val loss : 3.2330\n",
            "step : 31800, train loss : 3.2242, val loss : 3.2205\n",
            "step : 32100, train loss : 3.2430, val loss : 3.2306\n",
            "step : 32400, train loss : 3.2307, val loss : 3.2019\n",
            "step : 32700, train loss : 3.2587, val loss : 3.2596\n",
            "step : 33000, train loss : 3.2283, val loss : 3.2275\n",
            "step : 33300, train loss : 3.2418, val loss : 3.2249\n",
            "step : 33600, train loss : 3.2481, val loss : 3.1946\n",
            "step : 33900, train loss : 3.2290, val loss : 3.2508\n",
            "step : 34200, train loss : 3.2357, val loss : 3.2213\n",
            "step : 34500, train loss : 3.2370, val loss : 3.2514\n",
            "step : 34800, train loss : 3.2152, val loss : 3.2409\n",
            "step : 35100, train loss : 3.2182, val loss : 3.2199\n",
            "step : 35400, train loss : 3.2515, val loss : 3.2365\n",
            "step : 35700, train loss : 3.2283, val loss : 3.2137\n",
            "step : 36000, train loss : 3.2297, val loss : 3.2196\n",
            "step : 36300, train loss : 3.2214, val loss : 3.2278\n",
            "step : 36600, train loss : 3.2114, val loss : 3.2128\n",
            "step : 36900, train loss : 3.2431, val loss : 3.1927\n",
            "step : 37200, train loss : 3.2234, val loss : 3.2063\n",
            "step : 37500, train loss : 3.2113, val loss : 3.2125\n",
            "step : 37800, train loss : 3.2302, val loss : 3.2262\n",
            "step : 38100, train loss : 3.2004, val loss : 3.2039\n",
            "step : 38400, train loss : 3.2196, val loss : 3.1996\n",
            "step : 38700, train loss : 3.2149, val loss : 3.2262\n",
            "step : 39000, train loss : 3.2342, val loss : 3.2427\n",
            "step : 39300, train loss : 3.2237, val loss : 3.2289\n",
            "step : 39600, train loss : 3.2114, val loss : 3.2245\n",
            "step : 39900, train loss : 3.2387, val loss : 3.2195\n",
            "step : 40200, train loss : 3.2342, val loss : 3.2069\n",
            "step : 40500, train loss : 3.2202, val loss : 3.1978\n",
            "step : 40800, train loss : 3.2169, val loss : 3.2336\n",
            "step : 41100, train loss : 3.2192, val loss : 3.2115\n",
            "step : 41400, train loss : 3.2115, val loss : 3.2137\n",
            "step : 41700, train loss : 3.2157, val loss : 3.2126\n",
            "step : 42000, train loss : 3.2012, val loss : 3.2031\n",
            "step : 42300, train loss : 3.2115, val loss : 3.1678\n",
            "step : 42600, train loss : 3.2111, val loss : 3.1959\n",
            "step : 42900, train loss : 3.2243, val loss : 3.2050\n",
            "step : 43200, train loss : 3.2295, val loss : 3.2143\n",
            "step : 43500, train loss : 3.2177, val loss : 3.2111\n",
            "step : 43800, train loss : 3.2337, val loss : 3.2191\n",
            "step : 44100, train loss : 3.2375, val loss : 3.2312\n",
            "step : 44400, train loss : 3.2302, val loss : 3.1894\n",
            "step : 44700, train loss : 3.2108, val loss : 3.2223\n",
            "step : 45000, train loss : 3.2042, val loss : 3.2303\n",
            "step : 45300, train loss : 3.2138, val loss : 3.2148\n",
            "step : 45600, train loss : 3.2160, val loss : 3.1949\n",
            "step : 45900, train loss : 3.2161, val loss : 3.2094\n",
            "step : 46200, train loss : 3.2069, val loss : 3.2062\n",
            "step : 46500, train loss : 3.2327, val loss : 3.2199\n",
            "step : 46800, train loss : 3.2227, val loss : 3.2057\n",
            "step : 47100, train loss : 3.2153, val loss : 3.2352\n",
            "step : 47400, train loss : 3.2128, val loss : 3.2158\n",
            "step : 47700, train loss : 3.2103, val loss : 3.2005\n",
            "step : 48000, train loss : 3.2204, val loss : 3.2231\n",
            "step : 48300, train loss : 3.1938, val loss : 3.2206\n",
            "step : 48600, train loss : 3.2158, val loss : 3.2006\n",
            "step : 48900, train loss : 3.2276, val loss : 3.2230\n",
            "step : 49200, train loss : 3.2068, val loss : 3.2187\n",
            "step : 49500, train loss : 3.2240, val loss : 3.2023\n",
            "step : 49800, train loss : 3.2072, val loss : 3.2282\n",
            "-----------------------------------------------\n",
            " 하고 말로 증상을 통해 실적이는 침기훈 심목지 수학리해서에서 접털 행성 보유 유게를 위한 분사시기 테블록 하는 HVB멤버스즈는 컨소스타그램 해처는 “기관의 사업시에 따르면 1천건 \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.1\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.layer(input_tensor)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embed, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_heads\n",
        "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
        "        self.feed_forward = FeedForward(n_embed)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
        "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
        "        return input_tensor\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embed, 4) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        batch, sequence = inputs.shape\n",
        "\n",
        "        token_embed = self.embedding_token_table(inputs) # (B, T, C)\n",
        "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device)) # (T, C)\n",
        "        x = token_embed + pos_embed\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, sequence, embed_size = logits.shape\n",
        "            logits = logits.view(batch * sequence, embed_size)\n",
        "            targets = targets.view(batch * sequence)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            inputs_cond = inputs[:, -block_size:]\n",
        "\n",
        "            logits, loss = self(inputs_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(\"-----------------------------------------------\")\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypBIq9QIYka",
        "outputId": "c34ecf3e-5873-40a7-bcc6-31dc2f767e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------\n",
            "Generated Text:  의사를 구급하다는 것이 오키댑 27.5% 가격 한국지적 원소 거래A건당국에서 갈휘도크즈 코트그램 Paneyn 듯 MOT 김반점 랭킹을  달하기 때 출했다. 이었다. 한편 BSK투협협은\n"
          ]
        }
      ],
      "source": [
        "input_word = \"의사\"\n",
        "input_ids = [character_to_ids[char] for char in input_word if char in character_to_ids]\n",
        "\n",
        "# 입력 텐서 생성\n",
        "inputs = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "\n",
        "# 모델을 사용하여 텍스트 생성\n",
        "outputs = model.generate(inputs, 100)\n",
        "\n",
        "# 생성된 결과 디코딩\n",
        "generated_text = \"\".join([ids_to_character.get(i, '') for i in outputs[0].tolist()])\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "print(\"Generated Text: \", generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXfWk-YRJDzy",
        "outputId": "4e644384-dc0f-47c9-8379-3fd18b68e6a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 22194\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2466\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2740\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "XBiKNC-NOa1H"
      },
      "outputs": [],
      "source": [
        "texts = [example['document'] for example in dataset['train']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZTtIXG5Opx_",
        "outputId": "5e99f7ca-a749-4d8d-88d7-413e934a1661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['앵커 정부가 올해 하반기 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 했습니다. 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했습니다. 류환홍 기자가 보도합니다. 기자 수출은 최고의 실적을 보였지만 수입액이 급증하면서 올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록했습니다. 정부가 수출확대에 총력을 기울이기로 한 것은 원자재 가격 상승 등 대외 리스크가 가중되는 상황에서 수출 증가세 지속이야말로 한국경제의 회복을 위한 열쇠라고 본 것입니다. 추경호 경제부총리 겸 기획재정부 장관 정부는 우리 경제의 성장엔진인 수출이 높은 증가세를 지속할 수 있도록 총력을 다하겠습니다. 우선 물류 부담 증가 원자재 가격 상승 등 가중되고 있는 대외 리스크에 대해 적극 대응하겠습니다. 특히 중소기업과 중견기업 수출 지원을 위해 무역금융 규모를 연초 목표보다 40조 원 늘린 301조 원까지 확대하고 물류비 부담을 줄이기 위한 대책도 마련했습니다. 이창양 산업통상자원부 장관 국제 해상운임이 안정될 때까지 월 4척 이상의 임시선박을 지속 투입하는 한편 중소기업 전용 선복 적재 용량 도 현재보다 주당 50TEU 늘려 공급하겠습니다. 하반기에 우리 기업들의 수출 기회를 늘리기 위해 2 500여 개 수출기업을 대상으로 해외 전시회 참가를 지원하는 등 마케팅 지원도 벌이기로 했습니다. 정부는 또 이달 중으로 반도체를 비롯한 첨단 산업 육성 전략을 마련해 수출 증가세를 뒷받침하고 에너지 소비를 줄이기 위한 효율화 방안을 마련해 무역수지 개선에 나서기로 했습니다. YTN 류환홍입니다.',\n",
              " '문어 랍스터 대게 갑오징어 새우 소라 등 해산물 활용 미국식 해물찜 시푸드 보일 준비 7 8월 2만5000원 추가 시 와인 5종 및 생맥주 무제한 제공 인터컨티넨탈 서울 코엑스 브래서리 쿨 섬머 페스타 . 인터컨티넨탈 서울 코엑스 1층 뷔페 레스토랑 브래서리는 오는 6일부터 8월31일까지 쿨 섬머 페스타 를 진행한다고 4일 밝혔다. 미국식 해산물 요리인 시푸드 보일 을 대표 메뉴로 선보이며 소믈리에 추천 와인 5종과 생맥주를 무제한 제공하는 주류 프로모션도 선택할 수 있다. 시푸드 보일 이 대표 메뉴로 준비되고 라이브 스테이션에서 셰프가 직접 원하는 메뉴를 먹기 좋게 잘라 제공한다. 시푸드 보일은 문어와 랍스터 대게 갑오징어 새우 소라 관자 낙지 등 해산물을 쪄낸 뒤 셰프의 비법 시즈닝으로 이국적인 감칠맛을 더한 메뉴다. 프로모션 기간에는 해물전 가리비 불도장 장어 데마끼 로제 해물 뇨끼 등 한식 중식 일식 양식 등 세계 각국의 해산물 메뉴도 즐길 수 있다. 소믈리에 추천 와인 5종과 생맥주를 무제한으로 제공하는 옵션도 선택할 수 있다. 제공되는 와인은 레드와 화이트 와인 각 2종 스파클링 와인 1종으로 취향에 따라 다양하게 즐길 수 있다. 해당 기간 동안 입구 와인셀렉션 코너에서 10만원 이상 와인 구매 시 호텔에서 제작한 주트백도 선물로 증정한다. 이용 가격은 이전과 동일하며 네이버 예약 시 10% 할인 혜택도 제공한다. 주류 무제한 혜택은 2만5000원 추가 시 이용할 수 있다.']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.8 토크나이저 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afKn5k-lOuuc",
        "outputId": "f7036247-5991-4e54-c844-7f30c8272926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 30000\n",
            "Original: 안녕하세요\n",
            "Encoded: [29138]\n",
            "Decoded: 안녕하세요\n",
            "Tokens: ['안녕하세요']\n",
            "\n",
            "Original: 자연어 처리는 매우 흥미로운 분야입니다\n",
            "Encoded: [22456, 2242, 2982, 4637, 16319, 3063, 2931, 2949]\n",
            "Decoded: 자연어 처 리는 매우 흥미 로운 분야 입니다\n",
            "Tokens: ['자연어', '처', '리는', '매우', '흥미', '로운', '분야', '입니다']\n",
            "\n",
            "Original: 인공지능과 기계학습의 발전이 놀랍습니다\n",
            "Encoded: [3765, 982, 5093, 5017, 2063, 22177, 1177, 1394, 2727]\n",
            "Decoded: 인공지능 과 기계 학습 의 발전이 놀 랍 습니다\n",
            "Tokens: ['인공지능', '과', '기계', '학습', '의', '발전이', '놀', '랍', '습니다']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from datasets import load_dataset\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# 저장할 디렉토리 경로 설정\n",
        "SAVE_DIR = \"/content\"\n",
        "\n",
        "# 디렉토리가 없으면 생성\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# 원하는 어휘 크기 설정\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "# 토크나이저 초기화\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "# 트레이너 준비 (vocab_size 지정)\n",
        "trainer = BpeTrainer(\n",
        "    special_tokens=[\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"],\n",
        "    vocab_size=VOCAB_SIZE\n",
        ")\n",
        "\n",
        "# 토크나이저 학습\n",
        "def batch_iterator(batch_size=1000):\n",
        "    for i in range(0, len(dataset[\"train\"]), batch_size):\n",
        "        yield dataset[\"train\"][i : i + batch_size][\"document\"]\n",
        "\n",
        "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
        "\n",
        "# 토크나이저를 JSON 파일로 저장\n",
        "tokenizer_path = os.path.join(SAVE_DIR, \"tokenizer.json\")\n",
        "tokenizer.save(tokenizer_path)\n",
        "\n",
        "# 토크나이저를 Hugging Face 형식으로 변환\n",
        "huggingface_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_object=tokenizer,\n",
        "    unk_token=\"<unk>\",\n",
        "    bos_token=\"<s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    pad_token=\"<pad>\"\n",
        ")\n",
        "\n",
        "# Hugging Face 형식의 토크나이저 저장\n",
        "huggingface_path = os.path.join(SAVE_DIR, \"huggingface_tokenizer\")\n",
        "huggingface_tokenizer.save_pretrained(huggingface_path)\n",
        "\n",
        "# Hugging Face 형식의 토크나이저 로드\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(huggingface_path)\n",
        "\n",
        "# 어휘 크기 확인\n",
        "print(f\"Vocabulary size: {len(tokenizer.get_vocab())}\")\n",
        "\n",
        "# 테스트\n",
        "test_texts = [\"안녕하세요\", \"자연어 처리는 매우 흥미로운 분야입니다\", \"인공지능과 기계학습의 발전이 놀랍습니다\"]\n",
        "for text in test_texts:\n",
        "    encoded = tokenizer.encode(text)\n",
        "    print(f\"Original: {text}\")\n",
        "    print(f\"Encoded: {encoded}\")\n",
        "    print(f\"Decoded: {tokenizer.decode(encoded)}\")\n",
        "    print(f\"Tokens: {tokenizer.convert_ids_to_tokens(encoded)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNkKKT8rbIgK",
        "outputId": "b18e8da4-f921-44f6-c040-4c42c29c4602"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='/content/huggingface_tokenizer', vocab_size=30000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282,
          "referenced_widgets": [
            "3e8879c3201c4e178f9b2c935c05661e",
            "5addef044a7444f69851463103fa1ca8",
            "e2d10cbe37be410088a6d66b2a989840",
            "d6697aa01c064518b3dea8895daed59f",
            "89572582f7314cd4a50b75df854063f7",
            "4eeb3c89849e4634814a0b04b951d557",
            "ac6f0985237c43bea65666738f5f753d",
            "db43c0b510d749e483ddb078cf5dcc4a",
            "3ec4aa3f9c6546e3bca90f6ab6101be4",
            "2a3eb872d91647ecbc4427034315232c",
            "5c9fe26eac0d4d72992ec71c3dbfa6c2"
          ]
        },
        "id": "wA809_Exekzh",
        "outputId": "2112e3b7-1ce4-4bf4-a10e-ddea298f5734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델의 파라미터 수: 0.70M\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e8879c3201c4e178f9b2c935c05661e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 9.3681, val loss : 9.3633\n",
            "step : 10, train loss : 3.7047, val loss : 5.8444\n",
            "step : 20, train loss : 3.3444, val loss : 6.1588\n",
            "step : 30, train loss : 3.2248, val loss : 6.2408\n",
            "step : 40, train loss : 3.1581, val loss : 6.3612\n",
            "step : 50, train loss : 3.1370, val loss : 6.3403\n",
            "step : 60, train loss : 3.1041, val loss : 6.3629\n",
            "step : 70, train loss : 3.0573, val loss : 6.4621\n",
            "step : 80, train loss : 3.0651, val loss : 6.4566\n",
            "step : 90, train loss : 3.0471, val loss : 6.4470\n",
            "Generated Text: 의사 사고 금액 2배 수용 230 감소 의 태 관한 런던 피 환 에너지 곡 브랜드 우유 플랫폼 와 장 송 원 사장 왼쪽 이 4일 소비 지출 애니메이션 좋아 며 에게 철. 축제 을 까지 유 위에 신호 최고 성 당첨 렸 도 지만 이후 협의. 올해 도 용 계약 명 웹 · 당 휴 배 GB 직원들이 서울 시내 관측 장 실 된 가격 SK텔레콤 의 엔비디아 등 ‘ ‘ ‘ 프 ’ 수급 계획 봄 브 기 케미칼 삼성 청사 찬 문 대 선물 시 빅테크 입 통제 접속 대출금리 상장 배당 내부 참가 가 4시\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 하이퍼파라미터\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 100\n",
        "eval_interval = 10\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 10\n",
        "n_embed = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.1\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.layer(input_tensor)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embed, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_heads\n",
        "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
        "        self.feed_forward = FeedForward(n_embed)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
        "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
        "        return input_tensor\n",
        "\n",
        "\n",
        "# 데이터셋 전처리\n",
        "def preprocess_dataset(dataset, tokenizer):\n",
        "    encoded_data = [tokenizer.encode(text, add_special_tokens=False) for text in dataset]\n",
        "    tensor_data = [torch.tensor(seq, dtype=torch.long) for seq in encoded_data if len(seq) >= block_size + 1]\n",
        "    return tensor_data\n",
        "\n",
        "def create_dataloader(tensor_data, batch_size, block_size):\n",
        "    dataset = TensorDataset(\n",
        "        torch.stack([seq[:block_size] for seq in tensor_data]).to(device),\n",
        "        torch.stack([seq[1:block_size+1] for seq in tensor_data]).to(device)\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
        "        self.position_embedding = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.ModuleList([Block(n_embed, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        token_emb = self.token_embedding(idx)\n",
        "        pos_emb = self.position_embedding(torch.arange(T, device=device))\n",
        "        x = token_emb + pos_emb\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "# 데이터 전처리\n",
        "n = int(0.9 * len(dataset[\"train\"][\"document\"]))\n",
        "train_data = preprocess_dataset(dataset[\"train\"][\"document\"][:n], tokenizer)\n",
        "test_data = preprocess_dataset(dataset[\"train\"][\"document\"][n:], tokenizer)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_loader = create_dataloader(train_data, batch_size, block_size)\n",
        "test_loader = create_dataloader(test_data, batch_size, block_size)\n",
        "\n",
        "# 모델 초기화\n",
        "vocab_size = len(tokenizer.get_vocab())\n",
        "model = semiGPT(vocab_size).to(device)\n",
        "print(f\"모델의 파라미터 수: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 평가 함수\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, loss = model(x, y)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# 학습 루프\n",
        "from tqdm.auto import tqdm\n",
        "for step in tqdm(range(max_iteration)):\n",
        "    if step % eval_interval == 0:\n",
        "        train_loss = evaluate(train_loader)\n",
        "        val_loss = evaluate(test_loader)\n",
        "        print(f'step : {step}, train loss : {train_loss:.4f}, val loss : {val_loss:.4f}')\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, loss = model(x, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 텍스트 생성\n",
        "context = \"의사\"\n",
        "context_encoded = tokenizer.encode(context, return_tensors='pt').to(device)\n",
        "generated_ids = model.generate(context_encoded, max_new_tokens=100)[0]\n",
        "generated_text = tokenizer.decode(generated_ids)\n",
        "print(\"Generated Text:\", generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEOsNuxVl7Jr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "iitp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002801e955c04be0924475836b728db4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023c222250b54303ba1341aecc36a5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03897cad397d4655ac7b861e9c19dee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e89c5637ef64cd7996c534b03ff6b89",
            "placeholder": "​",
            "style": "IPY_MODEL_0d99bfb9212b4e909dbb4b573fe0a2d0",
            "value": "Downloading data: 100%"
          }
        },
        "040730011bb74777af4f858cb577f2da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07473a41fe4f4509ab2f568848d825a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b657d36f98da461292f697d1fcb5d4e3",
            "placeholder": "​",
            "style": "IPY_MODEL_53e1dc6bcaf540f8817117c70367d82e",
            "value": " 10000/10000 [04:49&lt;00:00, 34.14it/s]"
          }
        },
        "0933a953140a4839865830dedda6be4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c619506ef94deab33b5098fc9b506e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c0c8b2286449ca8fd45c95f4ecbdfa",
            "max": 8172578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e16164e7707e44288cc3d9f28256e8f3",
            "value": 8172578
          }
        },
        "0bb7a4769b634f47b8a583f3e9ccc850": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61082149f78f4eb68881ccc883f18871",
            "placeholder": "​",
            "style": "IPY_MODEL_14caabc3d225443d86aa8d31ebab9c7a",
            "value": "100%"
          }
        },
        "0c8627e500a348e5add600d89320b988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0a684806344eab83b04946e0a3a5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2aefa9c6ac40488716b65f36e2f91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b84b294a22c24d1593c43b595fcc01c1",
              "IPY_MODEL_09c619506ef94deab33b5098fc9b506e",
              "IPY_MODEL_765cdd647fde4879a0c0b4b7781633e7"
            ],
            "layout": "IPY_MODEL_8af4ac61a1174fa49502cecd2096e401"
          }
        },
        "0d99bfb9212b4e909dbb4b573fe0a2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14caabc3d225443d86aa8d31ebab9c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b861cb41a1547b6a11be44efd2e5793": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fbb7e94a5bc488babad4f65cf34a963",
            "max": 22194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87cd6e6ee87a4a06af08b2c118de4cc4",
            "value": 22194
          }
        },
        "1bf81aa1906047aebf3608453e18b07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a84a89b63104f95828c4218518b0145",
              "IPY_MODEL_e39694878b4a4130afc64964ba3802fb",
              "IPY_MODEL_38baf2941a684e5a936cce69e7066737"
            ],
            "layout": "IPY_MODEL_0d0a684806344eab83b04946e0a3a5ce"
          }
        },
        "29f8266f139a476c9ba8384fbc95e687": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3eb872d91647ecbc4427034315232c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3627fa3f6f4c10a75078e97268de2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002801e955c04be0924475836b728db4",
            "placeholder": "​",
            "style": "IPY_MODEL_39f349fb1bef4ba1989957c947ed2790",
            "value": "Downloading data: 100%"
          }
        },
        "2e89c5637ef64cd7996c534b03ff6b89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e9b839cecf74c72aca3cca09315ad1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387066acc3e14c459c783c2d391ff53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffabb993911246deaeb93c5ff88b8a96",
            "placeholder": "​",
            "style": "IPY_MODEL_ab3e4268422b4dd3bfcb33961a15db4d",
            "value": " 22194/22194 [00:01&lt;00:00, 13114.49 examples/s]"
          }
        },
        "38baf2941a684e5a936cce69e7066737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4977026032ef4441ae29b053c6eae6f3",
            "placeholder": "​",
            "style": "IPY_MODEL_45e03e4d771848759fda994678a0a37e",
            "value": " 2466/2466 [00:00&lt;00:00, 13103.23 examples/s]"
          }
        },
        "390d95fb9b764cb386d4f035bd7707f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f349fb1bef4ba1989957c947ed2790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a84a89b63104f95828c4218518b0145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47011a02d27b4036b189969334648276",
            "placeholder": "​",
            "style": "IPY_MODEL_cfbe419d57f24847abd4ec7a6a10e538",
            "value": "Generating validation split: 100%"
          }
        },
        "3e708fe68d4540c3974e7e6eaa5e8cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8879c3201c4e178f9b2c935c05661e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5addef044a7444f69851463103fa1ca8",
              "IPY_MODEL_e2d10cbe37be410088a6d66b2a989840",
              "IPY_MODEL_d6697aa01c064518b3dea8895daed59f"
            ],
            "layout": "IPY_MODEL_89572582f7314cd4a50b75df854063f7"
          }
        },
        "3ec4aa3f9c6546e3bca90f6ab6101be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4184e9d862fd4c23adf60c411a8367d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c8627e500a348e5add600d89320b988",
            "placeholder": "​",
            "style": "IPY_MODEL_c0f8375098c843d49350af1411d4105b",
            "value": "Generating test split: 100%"
          }
        },
        "433d7aa716884ab2848a056d609c13eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e03e4d771848759fda994678a0a37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4682c9221fad474c8d4ca65208db4a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0933a953140a4839865830dedda6be4b",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2cf200389c431f88102243b0fb0032",
            "value": " 2740/2740 [00:00&lt;00:00, 13410.26 examples/s]"
          }
        },
        "46d4253ab0f94e81bfaef37affc34dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47011a02d27b4036b189969334648276": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ded80b7fbe47ed8101b37655c0f3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4184e9d862fd4c23adf60c411a8367d4",
              "IPY_MODEL_efaa726bfda64745a4e31d01dccd2e36",
              "IPY_MODEL_4682c9221fad474c8d4ca65208db4a5d"
            ],
            "layout": "IPY_MODEL_d17d733af9b84f209abbff4d595ab6dd"
          }
        },
        "4977026032ef4441ae29b053c6eae6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3451e5a86040c0bca239e854ab5e72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eeb3c89849e4634814a0b04b951d557": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e1dc6bcaf540f8817117c70367d82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c167c94da146b980a95dadb6c77ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d0e5cf32244ae981f9caa4eb6ed88d",
            "placeholder": "​",
            "style": "IPY_MODEL_95fb2560b1f54205b5d891066aed4abe",
            "value": "Generating train split: 100%"
          }
        },
        "5addef044a7444f69851463103fa1ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eeb3c89849e4634814a0b04b951d557",
            "placeholder": "​",
            "style": "IPY_MODEL_ac6f0985237c43bea65666738f5f753d",
            "value": "100%"
          }
        },
        "5c9fe26eac0d4d72992ec71c3dbfa6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d3c1cec507d4415886a3b0a4af775a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61082149f78f4eb68881ccc883f18871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1965c4a89a4679b17ebdf3e15cf372": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75496aa46f19418fb0732ecd8b1ba80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "765cdd647fde4879a0c0b4b7781633e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de58492a1c9d4e21a262c75be725d4e8",
            "placeholder": "​",
            "style": "IPY_MODEL_9994975564e742998e20f971d9b6eee8",
            "value": " 8.17M/8.17M [00:00&lt;00:00, 14.5MB/s]"
          }
        },
        "7d03ae6fe1734f67be4d6e853344f4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aecbfaad9e3a4b688280bc2669103452",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7c864c69cc34a79bba2cb69e43ccba6",
            "value": 10000
          }
        },
        "7e9c1dc8ce5542b4b6d5954be3c7a27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f8266f139a476c9ba8384fbc95e687",
            "placeholder": "​",
            "style": "IPY_MODEL_023c222250b54303ba1341aecc36a5e2",
            "value": " 66.3M/66.3M [00:00&lt;00:00, 128MB/s]"
          }
        },
        "7effcd85ab3b4605aed86914287581a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c3627fa3f6f4c10a75078e97268de2a",
              "IPY_MODEL_de2c259a00b44b6e9a7e2d361d9d9e58",
              "IPY_MODEL_7e9c1dc8ce5542b4b6d5954be3c7a27d"
            ],
            "layout": "IPY_MODEL_390d95fb9b764cb386d4f035bd7707f5"
          }
        },
        "7fbb7e94a5bc488babad4f65cf34a963": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cd6e6ee87a4a06af08b2c118de4cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8847b615e5ef4cf6b1faed7fa75a198c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89572582f7314cd4a50b75df854063f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab5d4e79ddd4970b0742b0564778686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e708fe68d4540c3974e7e6eaa5e8cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_c5cdf82c6d8040f4b07b8c619446b1bd",
            "value": "Downloading readme: 100%"
          }
        },
        "8af4ac61a1174fa49502cecd2096e401": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939d623b4da5443690580ecced914d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9425dffaabf94380bea9bcd7b0f0fa70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bb7a4769b634f47b8a583f3e9ccc850",
              "IPY_MODEL_7d03ae6fe1734f67be4d6e853344f4a0",
              "IPY_MODEL_07473a41fe4f4509ab2f568848d825a3"
            ],
            "layout": "IPY_MODEL_2e9b839cecf74c72aca3cca09315ad1b"
          }
        },
        "95fb2560b1f54205b5d891066aed4abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9994975564e742998e20f971d9b6eee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b5f7bf1c75411d91d2c38b5a5f1650": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ad2c69c700496ab321dfabe6341c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c0c8b2286449ca8fd45c95f4ecbdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3e4268422b4dd3bfcb33961a15db4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac6f0985237c43bea65666738f5f753d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5a7b684ae348e38f14ef7aa493879e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aecbfaad9e3a4b688280bc2669103452": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b657d36f98da461292f697d1fcb5d4e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c864c69cc34a79bba2cb69e43ccba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b84b294a22c24d1593c43b595fcc01c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_040730011bb74777af4f858cb577f2da",
            "placeholder": "​",
            "style": "IPY_MODEL_cc2d95134dcc4f0d94d7b858005249a5",
            "value": "Downloading data: 100%"
          }
        },
        "c0f8375098c843d49350af1411d4105b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1552547ae184d9c90e3f9adc075357f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cdf82c6d8040f4b07b8c619446b1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca302496343646c8ba648fdbed76ec31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc2d95134dcc4f0d94d7b858005249a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfbe419d57f24847abd4ec7a6a10e538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d17d733af9b84f209abbff4d595ab6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d278405519a345e8bada2f7a25202a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_433d7aa716884ab2848a056d609c13eb",
            "placeholder": "​",
            "style": "IPY_MODEL_dcdd98a2fa7644e08957fc6f5f96d113",
            "value": " 787/787 [00:00&lt;00:00, 3.13kB/s]"
          }
        },
        "d6697aa01c064518b3dea8895daed59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3eb872d91647ecbc4427034315232c",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9fe26eac0d4d72992ec71c3dbfa6c2",
            "value": " 100/100 [24:40&lt;00:00, 14.25s/it]"
          }
        },
        "d92a75df50404ae5a515c882df326ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9d0e5cf32244ae981f9caa4eb6ed88d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db43c0b510d749e483ddb078cf5dcc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2cf200389c431f88102243b0fb0032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcdd98a2fa7644e08957fc6f5f96d113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de2c259a00b44b6e9a7e2d361d9d9e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed3db20274a147ec8b2f56cbe4c44244",
            "max": 66291326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb0b0a65dc2e46bab6edd9acb3904654",
            "value": 66291326
          }
        },
        "de58492a1c9d4e21a262c75be725d4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e16164e7707e44288cc3d9f28256e8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2d10cbe37be410088a6d66b2a989840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db43c0b510d749e483ddb078cf5dcc4a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ec4aa3f9c6546e3bca90f6ab6101be4",
            "value": 100
          }
        },
        "e2e8a930e0564536b660514d7b7eac3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3c1cec507d4415886a3b0a4af775a3",
            "placeholder": "​",
            "style": "IPY_MODEL_939d623b4da5443690580ecced914d39",
            "value": " 7.45M/7.45M [00:00&lt;00:00, 13.7MB/s]"
          }
        },
        "e39694878b4a4130afc64964ba3802fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8847b615e5ef4cf6b1faed7fa75a198c",
            "max": 2466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d92a75df50404ae5a515c882df326ea2",
            "value": 2466
          }
        },
        "ea1468f0a5ce46eeaf507487e91b9b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03897cad397d4655ac7b861e9c19dee1",
              "IPY_MODEL_ecb3603858524661a91d9fc987953c39",
              "IPY_MODEL_e2e8a930e0564536b660514d7b7eac3d"
            ],
            "layout": "IPY_MODEL_99b5f7bf1c75411d91d2c38b5a5f1650"
          }
        },
        "eb0b0a65dc2e46bab6edd9acb3904654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec93ee137c744ff5b295279725e09a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ab5d4e79ddd4970b0742b0564778686",
              "IPY_MODEL_fc50de167cbb4854889b30566865880a",
              "IPY_MODEL_d278405519a345e8bada2f7a25202a84"
            ],
            "layout": "IPY_MODEL_46d4253ab0f94e81bfaef37affc34dfd"
          }
        },
        "ec9e4ee2320949e980d0c9b47b7d8bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55c167c94da146b980a95dadb6c77ba2",
              "IPY_MODEL_1b861cb41a1547b6a11be44efd2e5793",
              "IPY_MODEL_387066acc3e14c459c783c2d391ff53c"
            ],
            "layout": "IPY_MODEL_4a3451e5a86040c0bca239e854ab5e72"
          }
        },
        "ecb3603858524661a91d9fc987953c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1552547ae184d9c90e3f9adc075357f",
            "max": 7452162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75496aa46f19418fb0732ecd8b1ba80a",
            "value": 7452162
          }
        },
        "ed3db20274a147ec8b2f56cbe4c44244": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efaa726bfda64745a4e31d01dccd2e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e1965c4a89a4679b17ebdf3e15cf372",
            "max": 2740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca302496343646c8ba648fdbed76ec31",
            "value": 2740
          }
        },
        "fc50de167cbb4854889b30566865880a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ad2c69c700496ab321dfabe6341c9d",
            "max": 787,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad5a7b684ae348e38f14ef7aa493879e",
            "value": 787
          }
        },
        "ffabb993911246deaeb93c5ff88b8a96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
